{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKin Segmentation using deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets,models, transforms\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'# !pip install torchsummary \n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.backends.cudnn.benchmark=True\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Training and Testing Data using Data Loader with Data Augmentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('./Umbilicus_Skin_Detection/code/X_train.npy').astype('float32')\n",
    "Y_train = np.load('./Umbilicus_Skin_Detection/code/Y_train.npy')\n",
    "X_test = np.load('./Umbilicus_Skin_Detection/code/X_test.npy')\n",
    "Y_test = np.load('./Umbilicus_Skin_Detection/code/Y_test.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing  the data using the Formula (x-xmin/(xmax-xmin)) across each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalizing the data by using the Formula (x-xmin/(xmax-xmin))\n",
    "# normx_=(adultdata-adultdata.min(axis=0))/(adultdata.max(axis=0)-adultdata.min(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting and Loading Data in Data Loader\n",
    "* Train Data Loader has shuffle = True, so that it can shuffle data in each minibatch every epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the Data into Training and Test Data\n",
    "# X_train, X_test,Y_train,Y_test = train_test_split(normadultdata,adultlabels, test_size=0.15, shuffle = True)\n",
    "\n",
    "# batch_size\n",
    "batch = 16\n",
    "# Train Data Loader\n",
    "train = data_utils.TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(Y_train).float())\n",
    "train_loader = data_utils.DataLoader(train, batch_size=batch, shuffle=True)\n",
    "\n",
    "# Test Data loader\n",
    "test = data_utils.TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(Y_test).float())\n",
    "test_loader = data_utils.DataLoader(test,batch_size=batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showing the Training Data after Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data\n",
      "tensor([55., 98., 72.,  ..., 78., 74., 64.])\n",
      "Testing Label\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Preview the training data\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#     print(batch_idx)\n",
    "    print(\"Training Data\")\n",
    "    print(data[0])\n",
    "    print(\"Testing Label\")\n",
    "    print(target[0].item())\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Linear Neural Network\n",
    "* A simple fully connected network was used with activation function like ReLU and PReLU. \n",
    "* PReLU was used as it increased the accuracy, although this was very experimental, as replacing all the ReLUs by PreLU significantly reduce the accuracy.\n",
    "* As this is a binary classification problem, Sigmoid Activation is Used in the final layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Net(\n",
       "    (fc1): Linear(in_features=2000, out_features=256, bias=True)\n",
       "    (relu1): ReLU()\n",
       "    (dout): Dropout(p=0.2)\n",
       "    (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (relu2): ReLU()\n",
       "    (dout2): Dropout(p=0.2)\n",
       "    (fc3): Linear(in_features=128, out_features=32, bias=True)\n",
       "    (prelu): PReLU(num_parameters=1)\n",
       "    (out): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (out_act): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2000, 256)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dout = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dout2 = nn.Dropout(0.2)\n",
    "        self.fc3 = nn.Linear(128, 32)\n",
    "        self.prelu = nn.PReLU(1)\n",
    "        self.out = nn.Linear(32, 1)\n",
    "        self.out_act = nn.Sigmoid()\n",
    "    \n",
    "    def swish(self,x):\n",
    "        return x * torch.sigmoid(x)\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        inp = self.fc1(input_)\n",
    "        x = self.relu1(inp)\n",
    "        x = self.dout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dout2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.prelu(x)\n",
    "        x = self.out(x)\n",
    "        y = (self.out_act(x))\n",
    "        return y\n",
    "net = Net()\n",
    "net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1               [16, 1, 256]         512,256\n",
      "            Linear-2               [16, 1, 256]         512,256\n",
      "              ReLU-3               [16, 1, 256]               0\n",
      "              ReLU-4               [16, 1, 256]               0\n",
      "           Dropout-5               [16, 1, 256]               0\n",
      "           Dropout-6               [16, 1, 256]               0\n",
      "            Linear-7               [16, 1, 128]          32,896\n",
      "            Linear-8               [16, 1, 128]          32,896\n",
      "              ReLU-9               [16, 1, 128]               0\n",
      "             ReLU-10               [16, 1, 128]               0\n",
      "          Dropout-11               [16, 1, 128]               0\n",
      "          Dropout-12               [16, 1, 128]               0\n",
      "           Linear-13                [16, 1, 32]           4,128\n",
      "           Linear-14                [16, 1, 32]           4,128\n",
      "            PReLU-15                [16, 1, 32]               1\n",
      "           Linear-16                 [16, 1, 1]              33\n",
      "            PReLU-17                [16, 1, 32]               1\n",
      "          Sigmoid-18                 [16, 1, 1]               0\n",
      "              Net-19                 [16, 1, 1]               0\n",
      "           Linear-20                 [16, 1, 1]              33\n",
      "          Sigmoid-21                 [16, 1, 1]               0\n",
      "              Net-22                 [16, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 1,098,628\n",
      "Trainable params: 1,098,628\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 0.30\n",
      "Params size (MB): 4.19\n",
      "Estimated Total Size (MB): 4.61\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net,input_size = (1,2000),batch_size=batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Convolution Neural Network\n",
    "* Initially I tried using 2 and 3 layer convolutions with dropout(0.5) and batchregularization, but the accuracy varied between 69 - (75, 77 ) percent. Later on I shifted to VGG networks which gave better accuracy. \n",
    "* After Implementing different VGG Networks, VGG13 gave the best results. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Code Modified from  https://github.com/kuangliu/pytorch-cifar/blob/master/models/vgg.py\n",
    "# config = {\n",
    "#     'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "#     'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512 ,512, 'M', 512, 512, 'M'],\n",
    "#     'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "#     'VGG19': [64, 64, 'M', 128,'D', 128, 'M', 256,'D', 256, 256, 256, 'M', 512,'D', 512, 512, 512, 'M', 512,'D', 512, 512, 512, 'M'],\n",
    "# }\n",
    "\n",
    "\n",
    "# class VGG(nn.Module):\n",
    "#     def __init__(self, vgg_name):\n",
    "#         super(VGG, self).__init__()\n",
    "#         self.conv = self._make_layers(config[vgg_name])\n",
    "#         self.linear = self._make_layers_linear()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         out = self.conv(x)\n",
    "#         out = out.view(out.size(0), -1)\n",
    "#         out = self.linear(out)\n",
    "#         return out\n",
    "    \n",
    "#     def vis(self, x):\n",
    "#         out = self.conv(x)\n",
    "#         return out\n",
    "    \n",
    "#     def swish(self,x):\n",
    "#         return x * torch.sigmoid(x) # Tried using this, but as the error did not converge, not used later on.\n",
    "\n",
    "#     def _make_layers(self, config):\n",
    "#         layers = []\n",
    "#         in_channels = 3\n",
    "#         for x in config:\n",
    "#             if x == 'M':\n",
    "#                 layers += [nn.MaxPool2d(kernel_size=2, stride=2)] \n",
    "#             elif x == 'D':\n",
    "#                 layers+= [nn.Dropout(0.5)]\n",
    "#             else:\n",
    "#                 layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1), # Padding is adjusted \n",
    "#                                                                                # To presever spatial dimension. \n",
    "#                            nn.BatchNorm2d(x),\n",
    "#                            nn.ReLU(inplace=True)]#inplace=True, PReLU()\n",
    "#                 in_channels = x\n",
    "#         layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "#         return nn.Sequential(*layers)\n",
    "    \n",
    "#     def _make_layers_linear(self):\n",
    "#         layers = []\n",
    "# #         layers +=[nn.Linear(512, 256)]\n",
    "# #         layers+= [nn.Dropout(0.5)]\n",
    "#         layers += [nn.Linear(512, 10)]\n",
    "# #         layers += [nn.LogSoftmax(dim=1)]\n",
    "# #         layers += [nn.Linear(64, 5)]\n",
    "#         return nn.Sequential(*layers) # Try softmax here\n",
    "\n",
    "# net = VGG('VGG13')\n",
    "# # net = shufflenetv2\n",
    "# net.to(device)\n",
    "# if device == 'cuda':\n",
    "#     net = torch.nn.DataParallel(net)\n",
    "# torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.fc1 = nn.Linear(3072, 1536)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.dout = nn.Dropout(0.2)\n",
    "#         self.fc2 = nn.Linear(1536, 384)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.dout2 = nn.Dropout(0.2)\n",
    "#         self.fc3 = nn.Linear(384, 64)\n",
    "#         self.prelu = nn.PReLU(1)\n",
    "#         self.out = nn.Linear(64, 10)\n",
    "#         self.out_act = nn.LogSoftmax(dim =1)\n",
    "\n",
    "#     def swish(self,x):\n",
    "#         return x * torch.sigmoid(x)\n",
    "        \n",
    "#     def forward(self, input_):\n",
    "#         inpu = input_.view(input_.size(0), -1)\n",
    "#         x = self.fc1(inpu)\n",
    "#         x = self.relu1(x)\n",
    "#         x = self.dout(x)\n",
    "#         x = self.fc2(x)\n",
    "#         x = self.relu2(x)\n",
    "#         x = self.dout2(x)\n",
    "#         x = self.fc3(x)\n",
    "#         x = self.prelu(x)\n",
    "#         y = self.out(x)\n",
    "#         y = (self.out_act(x))\n",
    "#         return y\n",
    "# net = Net()\n",
    "# net.to(device)\n",
    "# if device == 'cuda':\n",
    "#     net = torch.nn.DataParallel(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If want to get a summary of the network uncomment the below line as well as the one in importing libraries.\n",
    "# summary(net,(3,32,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanations for Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Loss function used is cross entropy class as there are multiple classes (10)\n",
    "* The model architecture adopted was that of VGG 13. This is because: \n",
    "     * the accuracy was in the range of 64 – 71 percent with a 5 layer network (input – conv1 – conv2- linear - crossentropyloss) .\n",
    "    * Convolutions were used as the input is 2D images. \n",
    "    * Even after adding dropouts of 0.2 and 0.5 in between the convolution layers the accuracy did not improve.\n",
    "     * Conclusion: as the networks needs to learn RGB images and distinguish 10 labels, it will need more parameters to shatter the input space.  Also the images are very blurry, this adds on to the number of parameters needed as differentiating becomes more difficult.\n",
    "* VGG 11 also did not give accuracies above 75 percent. As I was able to get descent accuracy with Vgg 13, I did not experiment with this network.\n",
    "* The Optimizer with Vgg13 is taken as Adam, as it got me better accuracies than SGD. This may be because Adam is able to avoid local minima and does not get stuck. \n",
    "* Learning rate of 0.002 gets me a good error convergence graph. Increase the learning rate to 0.01 also gives similar results much faster, but then convergence graph is like a step function and therefore avoided.\n",
    "* Some other experimentation with dropouts and different activations like (swish, relu and Prelu) can be seen in the screen shot of the excel file I made in the Ipython Notebook.\n",
    "\n",
    "* Each filter or weights of the convolution layers is visualized, in the image shown below.\n",
    "    * The image is a representation of weights of the first kernel in each layer (only a depth size of 3 is visualized for each convolution layer)\n",
    "    * we can see that the weights initialized is different for each layer. ( as they have different colors).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizaing Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kernels(c, num_cols=6):\n",
    "    fig = plt.figure(figsize=(num_cols,num_cols))\n",
    "    for i in range(num_cols):\n",
    "        ax1 = fig.add_subplot(num_cols,num_cols,i+1)\n",
    "        ax1.imshow(c)\n",
    "        ax1.axis('off')\n",
    "        ax1.set_xticklabels([])\n",
    "        ax1.set_yticklabels([])\n",
    "        break\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing the weights of the first kernel in each linear layer\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3168x3168 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAYAAACqaXHeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAA0JJREFUeJztml1I01EYxjfTTVNn1CxtlYhDSyR0TepOE5E+rkTR1vfXykIskLrxpkBqFFbLPuzCoguluonEWdGnBeFFSimJkaHowuHEJZYLdft3I8Hrowe6ei/Oee6e42/j5fHdu3PO/npN03QyK4K7AG6pALgL4JYKgLsAbkkfQKToj0WbzsF35NS6WOLLLz6F173wZxIfuJwCTNOtK8Q7TlUDM7NUT3z84R/AZJhGiXcltwNjWj2sh8U5Sd8BKgDuArglfQDCIdi/Nx7WEtLHiffkrQdm1ppE/EwK5lw1WEy8dtwPzArnNGU8k8DYOwaIL8veCcyzUVj6J+k7QAXAXQC3hDMg46YP1vz1UXRBCwPzzUkZiwfvHD53pREfO4T/C58rSHx4bA0w599mEJ94PwCMSNJ3gAqAuwBuSR+AcAjqwjjgzGfowWrDcxw6jYlPiN/WfRaYJUE6GFtPXwKmImsH8V5nFjDd1Q3Ep7YcA0Yk6TtABcBdALeEM2C0wAJrhl/0s9vyajMwwa0G4kPR+N5pD34S76zJA8bR20e86yHOgJwLJ4k3rvy/H3qk7wAVAHcB3JI+AOEQjPfOwJqhvYf4qN8bgRmsMxE/VRMCJvPuV+KDYQMw9VdLiNfW4oCLmFeiMbDoDfiCkr4DVADcBXBLOAOiB8ZxMYbuaoxtHwEJOOjm6Gj+G2DeHbITv+z6CDBllS+Jb/QUAmPZTW+FQ7sA0enqFlibk/QdoALgLoBb0gcgHIK+wlWwtr+yi3h3Bw6mxwVu4ks/VACTPkFPg5P7TMA8cucQb3X1AjNwj55Yl9vjgBFJ+g5QAXAXwC296FHZolx8RigURw8t3rwYfNN5Zx8tG3/Wvm1rIt6VmQvMRAmdAXFH8BmhqBO0HmvzEDA3bM3qGaHFpALgLoBb0gcg3AhpnV9gLeG9mfiR1nRgOqvoRmj7AdwI1c4eJN7xqQ2YOy4b8f3fk4Ax1v4h3u9LBUYk6TtABcBdALeEMyAyGT9zY0F6I2TuwZvj4vxy4qfcE8DYE4eJv9ZXAMy0lfpSO94+vW7YQrxlj+ChwAUkfQeoALgL4Jb0AQhPgzJI+g5QAXAXwC0VAHcB3JI+gL8lVcIbz/oR2AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 792x792 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAYAAACqaXHeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAAXNJREFUeJztm0ErRGEYRt8rNbGZKHcn/sBMsRJbi0nZT4Z/MKUUpWxsLFnIT5CyoCysJywUYWc9CyyVspKuP3D7esriLL7nLO+8vXM6fTVft6aoqipyZoQWoHEAWoDGAWgBmtHUh62tI+knYmLlXfqy8d63NBcRcfZ8Jc2t9jelubuL7aLuefYnwAFoARoHoAVoHIAWoHEAWoAmeRNc3riXlrx2Z6W548dLaS4iYvFkR5r7nf/f+4zsT4AD0AI0DkAL0DgALUDjALQATfImuFveSkvWplrS3MFHR5qLiGh8aje88vBJW7hX/zj7E+AAtACNA9ACNA5AC9A4AC1Ak32A5FW4N70kLflaH5PmHs7b0lxExOTwR5orBw15Zx3ZnwAHoAVoHIAWoHEAWoDGAWgBmuRN8PpNe+HY6c5Jc83TF2kuImK4vyDNDWZu5J11ZH8CHIAWoHEAWoDGAWgBGgegBWgK/3EycxyAFqBxAFqAJvsAf/+MLrOlP6cuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visnet = Net()\n",
    "visnet = visnet.double()\n",
    "print(\"Showing the weights of the first kernel in each linear layer\")\n",
    "for m in visnet.modules():\n",
    "    if isinstance(m, nn.Linear):   \n",
    "        a = m.weight.data.numpy()\n",
    "#         print(tensor.max())\n",
    "        c = (a - np.min(a))/np.ptp(a).astype(float)\n",
    "        ncols =np.floor(np.sqrt(c.shape[1])).astype(int)\n",
    "        c = np.reshape(c[0][0:ncols*ncols],(ncols,-1))\n",
    "        plot_kernels(c,ncols)\n",
    "#         break"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Define a Loss function and optimizer\n",
    "* Cross Entropy Loss is used as there are multiiple classes (5). \n",
    "* Different Permuation of the learning rate and optimizers were tried. The table I created for getting intition for accuracy and error can be found below or attached with homework sumission.\n",
    "![image.png](attachment:image.png)\n",
    "* After all the experimentation, the original vgg 13 network worked the best. Adding dropouts did not help, I guess this is due to not adding them at the right position. I also tried increasing the fully connected layers but it did not help.\n",
    "* The most significant discrepancy was found that, when not using softmax layer or log softmax layer, the testing accuracy actually came out to be more. I dont know why this happened!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.BCELoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9,weight_decay = 5e-4)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.002, betas=(0.9, 0.999), eps=1e-08, weight_decay= 5e-4)\n",
    "train_loss =[]\n",
    "val_loss = []\n",
    "train_accu = []\n",
    "test_accu=[]\n",
    "best_acc= 0  # best test accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # For Debugging\n",
    "# var=0\n",
    "# for batch_idx, (data, target) in enumerate(train_loader):\n",
    "# #     print(batch_idx)\n",
    "#     data, target = data.to(device), target.to(device)\n",
    "#     output = net(data)\n",
    "# #     print(target)\n",
    "# # # #         print(target.dtype,output.dtype)\n",
    "#     loss = criterion(output, target.flatten())\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     var += (torch.sum(torch.round(output)==target.view(-1,1))).item()\n",
    "\n",
    "#     break\n",
    "# # # target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch,device):\n",
    "#     print(criterion)\n",
    "    training_loss = 0\n",
    "    train_correct = 0\n",
    "    lo = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        #==== Forward Pass=====\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target.flatten())\n",
    "        #=====Backward Pass=======\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #=== Loss Append to get loss of entire Batch====\n",
    "        lo.append(loss.item())\n",
    "        #==== Calculating Training Accuracy========= \n",
    "        train_correct +=(torch.sum(torch.round(output)==target.view(-1,1))).item()\n",
    "        #======= Logging results after every 20th batch============ \n",
    "        if batch_idx % 20 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "    #======== Getting Accuracy of the entire epoch by averaging of each batch===========    \n",
    "    train_accu.append(100. * train_correct / len(train_loader.dataset))\n",
    "    #======== Getting Training Loss of the epoch by averaging across each batch\n",
    "    train_loss.append(np.mean(lo))\n",
    "\n",
    "def test(model, test_loader,device):\n",
    "    global best_acc\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    testlo = []\n",
    "    with torch.no_grad(): # as we dont need to backpropogate when calculating testing error and accuracy\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            #==== Getting the Prediction======\n",
    "            output = model(data)\n",
    "            #===== Calculating the Loss=========\n",
    "            test_loss = criterion(output, target.flatten())\n",
    "            testlo.append(test_loss.item())\n",
    "            # Calculating Testing Accuracy for the all inputs=========\n",
    "            correct += (torch.sum(torch.round(output)==target.view(-1,1))).item()\n",
    "    #======= Getting Testing Accuracy for the Epoch========\n",
    "    test_accu.append(100. * correct / len(test_loader.dataset))\n",
    "    #====== Getting Testing Error of Epoch========\n",
    "    val_loss.append(np.mean(testlo))\n",
    "   #======= Logging results after every epoch ============ \n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        np.mean(testlo), correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/len(test_loader.dataset)\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': model.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "            'val_loss': val_loss,\n",
    "            'test_accu': test_accu, \n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt.t7')\n",
    "    best_acc = acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume trained network if needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0 # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "# print('==> Resuming from checkpoint..')\n",
    "# assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "# checkpoint = torch.load('./checkpoint/ckpt.t7')\n",
    "# net.load_state_dict(checkpoint['net'])\n",
    "# best_acc = checkpoint['acc']\n",
    "# start_epoch = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a= net.state_dict(checkpoint['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anirudh/detect/lib/python3.5/site-packages/torch/nn/functional.py:1594: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/1196 (0%)]\tLoss: 1.696446\n",
      "Train Epoch: 0 [320/1196 (27%)]\tLoss: 15.542450\n",
      "Train Epoch: 0 [640/1196 (53%)]\tLoss: 17.269388\n",
      "Train Epoch: 0 [960/1196 (80%)]\tLoss: 17.269388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anirudh/detect/lib/python3.5/site-packages/torch/nn/functional.py:1594: UserWarning: Using a target size (torch.Size([12])) that is different to the input size (torch.Size([12, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 1 [0/1196 (0%)]\tLoss: 8.634694\n",
      "Train Epoch: 1 [320/1196 (27%)]\tLoss: 17.269388\n",
      "Train Epoch: 1 [640/1196 (53%)]\tLoss: 12.088572\n",
      "Train Epoch: 1 [960/1196 (80%)]\tLoss: 15.542450\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 2 [0/1196 (0%)]\tLoss: 12.088572\n",
      "Train Epoch: 2 [320/1196 (27%)]\tLoss: 25.904083\n",
      "Train Epoch: 2 [640/1196 (53%)]\tLoss: 6.907755\n",
      "Train Epoch: 2 [960/1196 (80%)]\tLoss: 15.542450\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 3 [0/1196 (0%)]\tLoss: 6.907755\n",
      "Train Epoch: 3 [320/1196 (27%)]\tLoss: 13.815511\n",
      "Train Epoch: 3 [640/1196 (53%)]\tLoss: 22.450205\n",
      "Train Epoch: 3 [960/1196 (80%)]\tLoss: 12.088572\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 4 [0/1196 (0%)]\tLoss: 12.088572\n",
      "Train Epoch: 4 [320/1196 (27%)]\tLoss: 13.815511\n",
      "Train Epoch: 4 [640/1196 (53%)]\tLoss: 15.542450\n",
      "Train Epoch: 4 [960/1196 (80%)]\tLoss: 15.542450\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 5 [0/1196 (0%)]\tLoss: 12.088573\n",
      "Train Epoch: 5 [320/1196 (27%)]\tLoss: 15.542450\n",
      "Train Epoch: 5 [640/1196 (53%)]\tLoss: 13.815511\n",
      "Train Epoch: 5 [960/1196 (80%)]\tLoss: 13.815511\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 6 [0/1196 (0%)]\tLoss: 12.088572\n",
      "Train Epoch: 6 [320/1196 (27%)]\tLoss: 13.815511\n",
      "Train Epoch: 6 [640/1196 (53%)]\tLoss: 13.815511\n",
      "Train Epoch: 6 [960/1196 (80%)]\tLoss: 10.361633\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 7 [0/1196 (0%)]\tLoss: 15.542450\n",
      "Train Epoch: 7 [320/1196 (27%)]\tLoss: 10.361633\n",
      "Train Epoch: 7 [640/1196 (53%)]\tLoss: 10.361633\n",
      "Train Epoch: 7 [960/1196 (80%)]\tLoss: 20.723267\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 8 [0/1196 (0%)]\tLoss: 8.634694\n",
      "Train Epoch: 8 [320/1196 (27%)]\tLoss: 15.542450\n",
      "Train Epoch: 8 [640/1196 (53%)]\tLoss: 15.542450\n",
      "Train Epoch: 8 [960/1196 (80%)]\tLoss: 18.996326\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 9 [0/1196 (0%)]\tLoss: 12.088572\n",
      "Train Epoch: 9 [320/1196 (27%)]\tLoss: 17.269388\n",
      "Train Epoch: 9 [640/1196 (53%)]\tLoss: 10.361633\n",
      "Train Epoch: 9 [960/1196 (80%)]\tLoss: 13.815511\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 10 [0/1196 (0%)]\tLoss: 15.542450\n",
      "Train Epoch: 10 [320/1196 (27%)]\tLoss: 17.269388\n",
      "Train Epoch: 10 [640/1196 (53%)]\tLoss: 18.996326\n",
      "Train Epoch: 10 [960/1196 (80%)]\tLoss: 15.542450\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 11 [0/1196 (0%)]\tLoss: 12.088572\n",
      "Train Epoch: 11 [320/1196 (27%)]\tLoss: 15.542450\n",
      "Train Epoch: 11 [640/1196 (53%)]\tLoss: 12.088572\n",
      "Train Epoch: 11 [960/1196 (80%)]\tLoss: 8.634694\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 12 [0/1196 (0%)]\tLoss: 15.542450\n",
      "Train Epoch: 12 [320/1196 (27%)]\tLoss: 17.269388\n",
      "Train Epoch: 12 [640/1196 (53%)]\tLoss: 10.361633\n",
      "Train Epoch: 12 [960/1196 (80%)]\tLoss: 12.088572\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 13 [0/1196 (0%)]\tLoss: 13.815511\n",
      "Train Epoch: 13 [320/1196 (27%)]\tLoss: 17.269388\n",
      "Train Epoch: 13 [640/1196 (53%)]\tLoss: 12.088572\n",
      "Train Epoch: 13 [960/1196 (80%)]\tLoss: 8.634694\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 14 [0/1196 (0%)]\tLoss: 17.269388\n",
      "Train Epoch: 14 [320/1196 (27%)]\tLoss: 12.088572\n",
      "Train Epoch: 14 [640/1196 (53%)]\tLoss: 8.634694\n",
      "Train Epoch: 14 [960/1196 (80%)]\tLoss: 13.815511\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 15 [0/1196 (0%)]\tLoss: 8.634694\n",
      "Train Epoch: 15 [320/1196 (27%)]\tLoss: 13.815511\n",
      "Train Epoch: 15 [640/1196 (53%)]\tLoss: 18.996326\n",
      "Train Epoch: 15 [960/1196 (80%)]\tLoss: 15.542450\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 16 [0/1196 (0%)]\tLoss: 10.361633\n",
      "Train Epoch: 16 [320/1196 (27%)]\tLoss: 12.088572\n",
      "Train Epoch: 16 [640/1196 (53%)]\tLoss: 17.269388\n",
      "Train Epoch: 16 [960/1196 (80%)]\tLoss: 12.088572\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 17 [0/1196 (0%)]\tLoss: 12.088572\n",
      "Train Epoch: 17 [320/1196 (27%)]\tLoss: 17.269388\n",
      "Train Epoch: 17 [640/1196 (53%)]\tLoss: 20.723267\n",
      "Train Epoch: 17 [960/1196 (80%)]\tLoss: 15.542450\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 18 [0/1196 (0%)]\tLoss: 15.542450\n",
      "Train Epoch: 18 [320/1196 (27%)]\tLoss: 13.815511\n",
      "Train Epoch: 18 [640/1196 (53%)]\tLoss: 12.088572\n",
      "Train Epoch: 18 [960/1196 (80%)]\tLoss: 15.542450\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 19 [0/1196 (0%)]\tLoss: 15.542450\n",
      "Train Epoch: 19 [320/1196 (27%)]\tLoss: 12.088572\n",
      "Train Epoch: 19 [640/1196 (53%)]\tLoss: 18.996326\n",
      "Train Epoch: 19 [960/1196 (80%)]\tLoss: 13.815511\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 20 [0/1196 (0%)]\tLoss: 13.815511\n",
      "Train Epoch: 20 [320/1196 (27%)]\tLoss: 12.088572\n",
      "Train Epoch: 20 [640/1196 (53%)]\tLoss: 12.088572\n",
      "Train Epoch: 20 [960/1196 (80%)]\tLoss: 13.815511\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 21 [0/1196 (0%)]\tLoss: 17.269388\n",
      "Train Epoch: 21 [320/1196 (27%)]\tLoss: 15.542450\n",
      "Train Epoch: 21 [640/1196 (53%)]\tLoss: 12.088572\n",
      "Train Epoch: 21 [960/1196 (80%)]\tLoss: 13.815511\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 22 [0/1196 (0%)]\tLoss: 13.815511\n",
      "Train Epoch: 22 [320/1196 (27%)]\tLoss: 17.269388\n",
      "Train Epoch: 22 [640/1196 (53%)]\tLoss: 13.815511\n",
      "Train Epoch: 22 [960/1196 (80%)]\tLoss: 15.542450\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 23 [0/1196 (0%)]\tLoss: 15.542450\n",
      "Train Epoch: 23 [320/1196 (27%)]\tLoss: 12.088572\n",
      "Train Epoch: 23 [640/1196 (53%)]\tLoss: 17.269388\n",
      "Train Epoch: 23 [960/1196 (80%)]\tLoss: 12.088572\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 24 [0/1196 (0%)]\tLoss: 15.542450\n",
      "Train Epoch: 24 [320/1196 (27%)]\tLoss: 10.361633\n",
      "Train Epoch: 24 [640/1196 (53%)]\tLoss: 20.723267\n",
      "Train Epoch: 24 [960/1196 (80%)]\tLoss: 6.907755\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 25 [0/1196 (0%)]\tLoss: 17.269388\n",
      "Train Epoch: 25 [320/1196 (27%)]\tLoss: 15.542450\n",
      "Train Epoch: 25 [640/1196 (53%)]\tLoss: 12.088572\n",
      "Train Epoch: 25 [960/1196 (80%)]\tLoss: 13.815511\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 26 [0/1196 (0%)]\tLoss: 18.996326\n",
      "Train Epoch: 26 [320/1196 (27%)]\tLoss: 10.361633\n",
      "Train Epoch: 26 [640/1196 (53%)]\tLoss: 12.088572\n",
      "Train Epoch: 26 [960/1196 (80%)]\tLoss: 17.269388\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 27 [0/1196 (0%)]\tLoss: 10.361633\n",
      "Train Epoch: 27 [320/1196 (27%)]\tLoss: 15.542450\n",
      "Train Epoch: 27 [640/1196 (53%)]\tLoss: 15.542450\n",
      "Train Epoch: 27 [960/1196 (80%)]\tLoss: 13.815511\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 28 [0/1196 (0%)]\tLoss: 8.634694\n",
      "Train Epoch: 28 [320/1196 (27%)]\tLoss: 17.269388\n",
      "Train Epoch: 28 [640/1196 (53%)]\tLoss: 12.088572\n",
      "Train Epoch: 28 [960/1196 (80%)]\tLoss: 15.542450\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 29 [0/1196 (0%)]\tLoss: 17.269388\n",
      "Train Epoch: 29 [320/1196 (27%)]\tLoss: 18.996326\n",
      "Train Epoch: 29 [640/1196 (53%)]\tLoss: 10.361633\n",
      "Train Epoch: 29 [960/1196 (80%)]\tLoss: 12.088572\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 30 [0/1196 (0%)]\tLoss: 13.815511\n",
      "Train Epoch: 30 [320/1196 (27%)]\tLoss: 10.361633\n",
      "Train Epoch: 30 [640/1196 (53%)]\tLoss: 13.815511\n",
      "Train Epoch: 30 [960/1196 (80%)]\tLoss: 13.815511\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 31 [0/1196 (0%)]\tLoss: 13.815511\n",
      "Train Epoch: 31 [320/1196 (27%)]\tLoss: 13.815511\n",
      "Train Epoch: 31 [640/1196 (53%)]\tLoss: 13.815511\n",
      "Train Epoch: 31 [960/1196 (80%)]\tLoss: 12.088572\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 32 [0/1196 (0%)]\tLoss: 6.907755\n",
      "Train Epoch: 32 [320/1196 (27%)]\tLoss: 13.815511\n",
      "Train Epoch: 32 [640/1196 (53%)]\tLoss: 12.088572\n",
      "Train Epoch: 32 [960/1196 (80%)]\tLoss: 10.361633\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 33 [0/1196 (0%)]\tLoss: 17.269388\n",
      "Train Epoch: 33 [320/1196 (27%)]\tLoss: 22.450205\n",
      "Train Epoch: 33 [640/1196 (53%)]\tLoss: 6.907755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 33 [960/1196 (80%)]\tLoss: 13.815511\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 34 [0/1196 (0%)]\tLoss: 13.815511\n",
      "Train Epoch: 34 [320/1196 (27%)]\tLoss: 13.815511\n",
      "Train Epoch: 34 [640/1196 (53%)]\tLoss: 18.996326\n",
      "Train Epoch: 34 [960/1196 (80%)]\tLoss: 18.996326\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 35 [0/1196 (0%)]\tLoss: 15.542450\n",
      "Train Epoch: 35 [320/1196 (27%)]\tLoss: 12.088572\n",
      "Train Epoch: 35 [640/1196 (53%)]\tLoss: 15.542450\n",
      "Train Epoch: 35 [960/1196 (80%)]\tLoss: 12.088572\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 36 [0/1196 (0%)]\tLoss: 17.269388\n",
      "Train Epoch: 36 [320/1196 (27%)]\tLoss: 13.815511\n",
      "Train Epoch: 36 [640/1196 (53%)]\tLoss: 22.450205\n",
      "Train Epoch: 36 [960/1196 (80%)]\tLoss: 18.996326\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 37 [0/1196 (0%)]\tLoss: 18.996326\n",
      "Train Epoch: 37 [320/1196 (27%)]\tLoss: 18.996326\n",
      "Train Epoch: 37 [640/1196 (53%)]\tLoss: 12.088572\n",
      "Train Epoch: 37 [960/1196 (80%)]\tLoss: 15.542450\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 38 [0/1196 (0%)]\tLoss: 18.996326\n",
      "Train Epoch: 38 [320/1196 (27%)]\tLoss: 15.542450\n",
      "Train Epoch: 38 [640/1196 (53%)]\tLoss: 15.542450\n",
      "Train Epoch: 38 [960/1196 (80%)]\tLoss: 13.815511\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 39 [0/1196 (0%)]\tLoss: 12.088573\n",
      "Train Epoch: 39 [320/1196 (27%)]\tLoss: 13.815511\n",
      "Train Epoch: 39 [640/1196 (53%)]\tLoss: 20.723267\n",
      "Train Epoch: 39 [960/1196 (80%)]\tLoss: 10.361633\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 40 [0/1196 (0%)]\tLoss: 12.088572\n",
      "Train Epoch: 40 [320/1196 (27%)]\tLoss: 10.361633\n",
      "Train Epoch: 40 [640/1196 (53%)]\tLoss: 13.815511\n",
      "Train Epoch: 40 [960/1196 (80%)]\tLoss: 8.634694\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 41 [0/1196 (0%)]\tLoss: 12.088572\n",
      "Train Epoch: 41 [320/1196 (27%)]\tLoss: 13.815511\n",
      "Train Epoch: 41 [640/1196 (53%)]\tLoss: 15.542450\n",
      "Train Epoch: 41 [960/1196 (80%)]\tLoss: 13.815511\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 42 [0/1196 (0%)]\tLoss: 13.815511\n",
      "Train Epoch: 42 [320/1196 (27%)]\tLoss: 15.542450\n",
      "Train Epoch: 42 [640/1196 (53%)]\tLoss: 15.542450\n",
      "Train Epoch: 42 [960/1196 (80%)]\tLoss: 17.269388\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 43 [0/1196 (0%)]\tLoss: 12.088572\n",
      "Train Epoch: 43 [320/1196 (27%)]\tLoss: 12.088572\n",
      "Train Epoch: 43 [640/1196 (53%)]\tLoss: 18.996326\n",
      "Train Epoch: 43 [960/1196 (80%)]\tLoss: 13.815511\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 44 [0/1196 (0%)]\tLoss: 13.815511\n",
      "Train Epoch: 44 [320/1196 (27%)]\tLoss: 6.907755\n",
      "Train Epoch: 44 [640/1196 (53%)]\tLoss: 13.815511\n",
      "Train Epoch: 44 [960/1196 (80%)]\tLoss: 10.361633\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 45 [0/1196 (0%)]\tLoss: 15.542450\n",
      "Train Epoch: 45 [320/1196 (27%)]\tLoss: 20.723267\n",
      "Train Epoch: 45 [640/1196 (53%)]\tLoss: 8.634694\n",
      "Train Epoch: 45 [960/1196 (80%)]\tLoss: 18.996326\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 46 [0/1196 (0%)]\tLoss: 12.088572\n",
      "Train Epoch: 46 [320/1196 (27%)]\tLoss: 13.815511\n",
      "Train Epoch: 46 [640/1196 (53%)]\tLoss: 13.815511\n",
      "Train Epoch: 46 [960/1196 (80%)]\tLoss: 13.815511\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 47 [0/1196 (0%)]\tLoss: 17.269388\n",
      "Train Epoch: 47 [320/1196 (27%)]\tLoss: 15.542450\n",
      "Train Epoch: 47 [640/1196 (53%)]\tLoss: 18.996326\n",
      "Train Epoch: 47 [960/1196 (80%)]\tLoss: 12.088572\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 48 [0/1196 (0%)]\tLoss: 10.361633\n",
      "Train Epoch: 48 [320/1196 (27%)]\tLoss: 6.907755\n",
      "Train Epoch: 48 [640/1196 (53%)]\tLoss: 17.269388\n",
      "Train Epoch: 48 [960/1196 (80%)]\tLoss: 12.088572\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 49 [0/1196 (0%)]\tLoss: 10.361633\n",
      "Train Epoch: 49 [320/1196 (27%)]\tLoss: 17.269388\n",
      "Train Epoch: 49 [640/1196 (53%)]\tLoss: 10.361633\n",
      "Train Epoch: 49 [960/1196 (80%)]\tLoss: 12.088572\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 50 [0/1196 (0%)]\tLoss: 13.815511\n",
      "Train Epoch: 50 [320/1196 (27%)]\tLoss: 8.634694\n",
      "Train Epoch: 50 [640/1196 (53%)]\tLoss: 13.815511\n",
      "Train Epoch: 50 [960/1196 (80%)]\tLoss: 17.269388\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 51 [0/1196 (0%)]\tLoss: 8.634694\n",
      "Train Epoch: 51 [320/1196 (27%)]\tLoss: 13.815511\n",
      "Train Epoch: 51 [640/1196 (53%)]\tLoss: 15.542450\n",
      "Train Epoch: 51 [960/1196 (80%)]\tLoss: 15.542450\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 52 [0/1196 (0%)]\tLoss: 12.088572\n",
      "Train Epoch: 52 [320/1196 (27%)]\tLoss: 13.815511\n",
      "Train Epoch: 52 [640/1196 (53%)]\tLoss: 10.361633\n",
      "Train Epoch: 52 [960/1196 (80%)]\tLoss: 8.634694\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 53 [0/1196 (0%)]\tLoss: 10.361633\n",
      "Train Epoch: 53 [320/1196 (27%)]\tLoss: 8.634694\n",
      "Train Epoch: 53 [640/1196 (53%)]\tLoss: 17.269388\n",
      "Train Epoch: 53 [960/1196 (80%)]\tLoss: 15.542450\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 54 [0/1196 (0%)]\tLoss: 15.542450\n",
      "Train Epoch: 54 [320/1196 (27%)]\tLoss: 10.361633\n",
      "Train Epoch: 54 [640/1196 (53%)]\tLoss: 12.088572\n",
      "Train Epoch: 54 [960/1196 (80%)]\tLoss: 18.996326\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 55 [0/1196 (0%)]\tLoss: 17.269388\n",
      "Train Epoch: 55 [320/1196 (27%)]\tLoss: 17.269388\n",
      "Train Epoch: 55 [640/1196 (53%)]\tLoss: 15.542449\n",
      "Train Epoch: 55 [960/1196 (80%)]\tLoss: 18.996326\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 56 [0/1196 (0%)]\tLoss: 22.450205\n",
      "Train Epoch: 56 [320/1196 (27%)]\tLoss: 18.996326\n",
      "Train Epoch: 56 [640/1196 (53%)]\tLoss: 17.269388\n",
      "Train Epoch: 56 [960/1196 (80%)]\tLoss: 13.815511\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 57 [0/1196 (0%)]\tLoss: 15.542450\n",
      "Train Epoch: 57 [320/1196 (27%)]\tLoss: 13.815511\n",
      "Train Epoch: 57 [640/1196 (53%)]\tLoss: 18.996326\n",
      "Train Epoch: 57 [960/1196 (80%)]\tLoss: 13.815511\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 58 [0/1196 (0%)]\tLoss: 17.269388\n",
      "Train Epoch: 58 [320/1196 (27%)]\tLoss: 10.361633\n",
      "Train Epoch: 58 [640/1196 (53%)]\tLoss: 6.907755\n",
      "Train Epoch: 58 [960/1196 (80%)]\tLoss: 8.634694\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 59 [0/1196 (0%)]\tLoss: 13.815511\n",
      "Train Epoch: 59 [320/1196 (27%)]\tLoss: 10.361633\n",
      "Train Epoch: 59 [640/1196 (53%)]\tLoss: 12.088572\n",
      "Train Epoch: 59 [960/1196 (80%)]\tLoss: 12.088572\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 60 [0/1196 (0%)]\tLoss: 15.542450\n",
      "Train Epoch: 60 [320/1196 (27%)]\tLoss: 12.088572\n",
      "Train Epoch: 60 [640/1196 (53%)]\tLoss: 15.542450\n",
      "Train Epoch: 60 [960/1196 (80%)]\tLoss: 10.361633\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 61 [0/1196 (0%)]\tLoss: 10.361633\n",
      "Train Epoch: 61 [320/1196 (27%)]\tLoss: 17.269388\n",
      "Train Epoch: 61 [640/1196 (53%)]\tLoss: 12.088572\n",
      "Train Epoch: 61 [960/1196 (80%)]\tLoss: 15.542450\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 62 [0/1196 (0%)]\tLoss: 10.361633\n",
      "Train Epoch: 62 [320/1196 (27%)]\tLoss: 20.723267\n",
      "Train Epoch: 62 [640/1196 (53%)]\tLoss: 17.269388\n",
      "Train Epoch: 62 [960/1196 (80%)]\tLoss: 17.269388\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 63 [0/1196 (0%)]\tLoss: 12.088572\n",
      "Train Epoch: 63 [320/1196 (27%)]\tLoss: 15.542450\n",
      "Train Epoch: 63 [640/1196 (53%)]\tLoss: 12.088572\n",
      "Train Epoch: 63 [960/1196 (80%)]\tLoss: 10.361633\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 64 [0/1196 (0%)]\tLoss: 17.269388\n",
      "Train Epoch: 64 [320/1196 (27%)]\tLoss: 10.361633\n",
      "Train Epoch: 64 [640/1196 (53%)]\tLoss: 18.996326\n",
      "Train Epoch: 64 [960/1196 (80%)]\tLoss: 10.361633\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 65 [0/1196 (0%)]\tLoss: 13.815511\n",
      "Train Epoch: 65 [320/1196 (27%)]\tLoss: 18.996326\n",
      "Train Epoch: 65 [640/1196 (53%)]\tLoss: 22.450205\n",
      "Train Epoch: 65 [960/1196 (80%)]\tLoss: 15.542450\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 66 [0/1196 (0%)]\tLoss: 15.542450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 66 [320/1196 (27%)]\tLoss: 10.361633\n",
      "Train Epoch: 66 [640/1196 (53%)]\tLoss: 12.088572\n",
      "Train Epoch: 66 [960/1196 (80%)]\tLoss: 15.542450\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 67 [0/1196 (0%)]\tLoss: 5.180817\n",
      "Train Epoch: 67 [320/1196 (27%)]\tLoss: 10.361633\n",
      "Train Epoch: 67 [640/1196 (53%)]\tLoss: 15.542450\n",
      "Train Epoch: 67 [960/1196 (80%)]\tLoss: 15.542450\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 68 [0/1196 (0%)]\tLoss: 17.269388\n",
      "Train Epoch: 68 [320/1196 (27%)]\tLoss: 15.542450\n",
      "Train Epoch: 68 [640/1196 (53%)]\tLoss: 17.269388\n",
      "Train Epoch: 68 [960/1196 (80%)]\tLoss: 18.996326\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 69 [0/1196 (0%)]\tLoss: 15.542450\n",
      "Train Epoch: 69 [320/1196 (27%)]\tLoss: 15.542450\n",
      "Train Epoch: 69 [640/1196 (53%)]\tLoss: 18.996326\n",
      "Train Epoch: 69 [960/1196 (80%)]\tLoss: 10.361633\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 70 [0/1196 (0%)]\tLoss: 10.361633\n",
      "Train Epoch: 70 [320/1196 (27%)]\tLoss: 10.361633\n",
      "Train Epoch: 70 [640/1196 (53%)]\tLoss: 15.542450\n",
      "Train Epoch: 70 [960/1196 (80%)]\tLoss: 15.542450\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 71 [0/1196 (0%)]\tLoss: 17.269388\n",
      "Train Epoch: 71 [320/1196 (27%)]\tLoss: 15.542450\n",
      "Train Epoch: 71 [640/1196 (53%)]\tLoss: 12.088572\n",
      "Train Epoch: 71 [960/1196 (80%)]\tLoss: 12.088572\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 72 [0/1196 (0%)]\tLoss: 17.269388\n",
      "Train Epoch: 72 [320/1196 (27%)]\tLoss: 10.361633\n",
      "Train Epoch: 72 [640/1196 (53%)]\tLoss: 13.815511\n",
      "Train Epoch: 72 [960/1196 (80%)]\tLoss: 8.634694\n",
      "\n",
      "Test set: Average loss: 13.8843, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 73 [0/1196 (0%)]\tLoss: 15.542450\n",
      "Train Epoch: 73 [320/1196 (27%)]\tLoss: 12.088572\n",
      "Train Epoch: 73 [640/1196 (53%)]\tLoss: 8.634694\n",
      "Train Epoch: 73 [960/1196 (80%)]\tLoss: 13.815511\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 74 [0/1196 (0%)]\tLoss: 10.361633\n",
      "Train Epoch: 74 [320/1196 (27%)]\tLoss: 17.269388\n",
      "Train Epoch: 74 [640/1196 (53%)]\tLoss: 10.361633\n",
      "Train Epoch: 74 [960/1196 (80%)]\tLoss: 15.542450\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 75 [0/1196 (0%)]\tLoss: 13.815511\n",
      "Train Epoch: 75 [320/1196 (27%)]\tLoss: 12.088572\n",
      "Train Epoch: 75 [640/1196 (53%)]\tLoss: 10.361633\n",
      "Train Epoch: 75 [960/1196 (80%)]\tLoss: 17.269388\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 76 [0/1196 (0%)]\tLoss: 13.815511\n",
      "Train Epoch: 76 [320/1196 (27%)]\tLoss: 13.815511\n",
      "Train Epoch: 76 [640/1196 (53%)]\tLoss: 13.815511\n",
      "Train Epoch: 76 [960/1196 (80%)]\tLoss: 18.996326\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 77 [0/1196 (0%)]\tLoss: 6.907755\n",
      "Train Epoch: 77 [320/1196 (27%)]\tLoss: 13.815511\n",
      "Train Epoch: 77 [640/1196 (53%)]\tLoss: 18.996326\n",
      "Train Epoch: 77 [960/1196 (80%)]\tLoss: 15.542450\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 78 [0/1196 (0%)]\tLoss: 15.542450\n",
      "Train Epoch: 78 [320/1196 (27%)]\tLoss: 13.815511\n",
      "Train Epoch: 78 [640/1196 (53%)]\tLoss: 17.269388\n",
      "Train Epoch: 78 [960/1196 (80%)]\tLoss: 12.088572\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 79 [0/1196 (0%)]\tLoss: 12.088572\n",
      "Train Epoch: 79 [320/1196 (27%)]\tLoss: 6.907755\n",
      "Train Epoch: 79 [640/1196 (53%)]\tLoss: 15.542450\n",
      "Train Epoch: 79 [960/1196 (80%)]\tLoss: 15.542450\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 80 [0/1196 (0%)]\tLoss: 15.542450\n",
      "Train Epoch: 80 [320/1196 (27%)]\tLoss: 15.542450\n",
      "Train Epoch: 80 [640/1196 (53%)]\tLoss: 17.269388\n",
      "Train Epoch: 80 [960/1196 (80%)]\tLoss: 18.996326\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 81 [0/1196 (0%)]\tLoss: 20.723267\n",
      "Train Epoch: 81 [320/1196 (27%)]\tLoss: 8.634694\n",
      "Train Epoch: 81 [640/1196 (53%)]\tLoss: 13.815511\n",
      "Train Epoch: 81 [960/1196 (80%)]\tLoss: 13.815511\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 82 [0/1196 (0%)]\tLoss: 10.361633\n",
      "Train Epoch: 82 [320/1196 (27%)]\tLoss: 12.088572\n",
      "Train Epoch: 82 [640/1196 (53%)]\tLoss: 18.996326\n",
      "Train Epoch: 82 [960/1196 (80%)]\tLoss: 15.542450\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 83 [0/1196 (0%)]\tLoss: 13.815511\n",
      "Train Epoch: 83 [320/1196 (27%)]\tLoss: 13.815511\n",
      "Train Epoch: 83 [640/1196 (53%)]\tLoss: 13.815511\n",
      "Train Epoch: 83 [960/1196 (80%)]\tLoss: 13.815511\n",
      "\n",
      "Test set: Average loss: 13.9661, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 84 [0/1196 (0%)]\tLoss: 10.361633\n",
      "Train Epoch: 84 [320/1196 (27%)]\tLoss: 10.361633\n",
      "Train Epoch: 84 [640/1196 (53%)]\tLoss: 15.542450\n",
      "Train Epoch: 84 [960/1196 (80%)]\tLoss: 5.180817\n",
      "\n",
      "Test set: Average loss: 14.0692, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 85 [0/1196 (0%)]\tLoss: 8.634694\n",
      "Train Epoch: 85 [320/1196 (27%)]\tLoss: 20.326153\n",
      "Train Epoch: 85 [640/1196 (53%)]\tLoss: 13.815511\n",
      "Train Epoch: 85 [960/1196 (80%)]\tLoss: 15.542450\n",
      "\n",
      "Test set: Average loss: 14.2272, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 86 [0/1196 (0%)]\tLoss: 13.815511\n",
      "Train Epoch: 86 [320/1196 (27%)]\tLoss: 15.542450\n",
      "Train Epoch: 86 [640/1196 (53%)]\tLoss: 20.723267\n",
      "Train Epoch: 86 [960/1196 (80%)]\tLoss: 12.088572\n",
      "\n",
      "Test set: Average loss: 14.4114, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 87 [0/1196 (0%)]\tLoss: 12.088572\n",
      "Train Epoch: 87 [320/1196 (27%)]\tLoss: 15.542450\n",
      "Train Epoch: 87 [640/1196 (53%)]\tLoss: 10.361633\n",
      "Train Epoch: 87 [960/1196 (80%)]\tLoss: 20.723267\n",
      "\n",
      "Test set: Average loss: 14.9306, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 88 [0/1196 (0%)]\tLoss: 17.269388\n",
      "Train Epoch: 88 [320/1196 (27%)]\tLoss: 15.542449\n",
      "Train Epoch: 88 [640/1196 (53%)]\tLoss: 13.815512\n",
      "Train Epoch: 88 [960/1196 (80%)]\tLoss: 12.088572\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 89 [0/1196 (0%)]\tLoss: 10.361633\n",
      "Train Epoch: 89 [320/1196 (27%)]\tLoss: 15.542450\n",
      "Train Epoch: 89 [640/1196 (53%)]\tLoss: 15.542450\n",
      "Train Epoch: 89 [960/1196 (80%)]\tLoss: 13.815511\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 90 [0/1196 (0%)]\tLoss: 18.996326\n",
      "Train Epoch: 90 [320/1196 (27%)]\tLoss: 15.542450\n",
      "Train Epoch: 90 [640/1196 (53%)]\tLoss: 12.088572\n",
      "Train Epoch: 90 [960/1196 (80%)]\tLoss: 15.542450\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 91 [0/1196 (0%)]\tLoss: 17.269388\n",
      "Train Epoch: 91 [320/1196 (27%)]\tLoss: 15.542450\n",
      "Train Epoch: 91 [640/1196 (53%)]\tLoss: 17.269388\n",
      "Train Epoch: 91 [960/1196 (80%)]\tLoss: 12.088572\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 92 [0/1196 (0%)]\tLoss: 10.361633\n",
      "Train Epoch: 92 [320/1196 (27%)]\tLoss: 13.815511\n",
      "Train Epoch: 92 [640/1196 (53%)]\tLoss: 20.723267\n",
      "Train Epoch: 92 [960/1196 (80%)]\tLoss: 13.815511\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 93 [0/1196 (0%)]\tLoss: 13.815511\n",
      "Train Epoch: 93 [320/1196 (27%)]\tLoss: 10.361633\n",
      "Train Epoch: 93 [640/1196 (53%)]\tLoss: 10.361633\n",
      "Train Epoch: 93 [960/1196 (80%)]\tLoss: 12.088572\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 94 [0/1196 (0%)]\tLoss: 12.088572\n",
      "Train Epoch: 94 [320/1196 (27%)]\tLoss: 12.088572\n",
      "Train Epoch: 94 [640/1196 (53%)]\tLoss: 17.269388\n",
      "Train Epoch: 94 [960/1196 (80%)]\tLoss: 8.634694\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 95 [0/1196 (0%)]\tLoss: 10.361633\n",
      "Train Epoch: 95 [320/1196 (27%)]\tLoss: 15.542450\n",
      "Train Epoch: 95 [640/1196 (53%)]\tLoss: 12.088572\n",
      "Train Epoch: 95 [960/1196 (80%)]\tLoss: 15.542450\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 96 [0/1196 (0%)]\tLoss: 15.542450\n",
      "Train Epoch: 96 [320/1196 (27%)]\tLoss: 18.996326\n",
      "Train Epoch: 96 [640/1196 (53%)]\tLoss: 13.815511\n",
      "Train Epoch: 96 [960/1196 (80%)]\tLoss: 13.815511\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 97 [0/1196 (0%)]\tLoss: 18.996326\n",
      "Train Epoch: 97 [320/1196 (27%)]\tLoss: 10.361633\n",
      "Train Epoch: 97 [640/1196 (53%)]\tLoss: 10.361633\n",
      "Train Epoch: 97 [960/1196 (80%)]\tLoss: 15.542450\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 98 [0/1196 (0%)]\tLoss: 5.180817\n",
      "Train Epoch: 98 [320/1196 (27%)]\tLoss: 10.361633\n",
      "Train Epoch: 98 [640/1196 (53%)]\tLoss: 8.634694\n",
      "Train Epoch: 98 [960/1196 (80%)]\tLoss: 13.815511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 99 [0/1196 (0%)]\tLoss: 13.815511\n",
      "Train Epoch: 99 [320/1196 (27%)]\tLoss: 15.542450\n",
      "Train Epoch: 99 [640/1196 (53%)]\tLoss: 18.996326\n",
      "Train Epoch: 99 [960/1196 (80%)]\tLoss: 17.269388\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 100 [0/1196 (0%)]\tLoss: 8.634694\n",
      "Train Epoch: 100 [320/1196 (27%)]\tLoss: 15.542450\n",
      "Train Epoch: 100 [640/1196 (53%)]\tLoss: 15.542450\n",
      "Train Epoch: 100 [960/1196 (80%)]\tLoss: 8.634694\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 101 [0/1196 (0%)]\tLoss: 17.269388\n",
      "Train Epoch: 101 [320/1196 (27%)]\tLoss: 20.723267\n",
      "Train Epoch: 101 [640/1196 (53%)]\tLoss: 8.634694\n",
      "Train Epoch: 101 [960/1196 (80%)]\tLoss: 8.634694\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 102 [0/1196 (0%)]\tLoss: 17.269388\n",
      "Train Epoch: 102 [320/1196 (27%)]\tLoss: 15.542450\n",
      "Train Epoch: 102 [640/1196 (53%)]\tLoss: 17.269388\n",
      "Train Epoch: 102 [960/1196 (80%)]\tLoss: 12.088572\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 103 [0/1196 (0%)]\tLoss: 13.815511\n",
      "Train Epoch: 103 [320/1196 (27%)]\tLoss: 13.815511\n",
      "Train Epoch: 103 [640/1196 (53%)]\tLoss: 6.907755\n",
      "Train Epoch: 103 [960/1196 (80%)]\tLoss: 12.088572\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 104 [0/1196 (0%)]\tLoss: 10.361633\n",
      "Train Epoch: 104 [320/1196 (27%)]\tLoss: 3.453878\n",
      "Train Epoch: 104 [640/1196 (53%)]\tLoss: 13.815511\n",
      "Train Epoch: 104 [960/1196 (80%)]\tLoss: 13.815511\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 105 [0/1196 (0%)]\tLoss: 15.542450\n",
      "Train Epoch: 105 [320/1196 (27%)]\tLoss: 12.088572\n",
      "Train Epoch: 105 [640/1196 (53%)]\tLoss: 18.996326\n",
      "Train Epoch: 105 [960/1196 (80%)]\tLoss: 17.269388\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 106 [0/1196 (0%)]\tLoss: 10.361633\n",
      "Train Epoch: 106 [320/1196 (27%)]\tLoss: 8.634694\n",
      "Train Epoch: 106 [640/1196 (53%)]\tLoss: 8.634694\n",
      "Train Epoch: 106 [960/1196 (80%)]\tLoss: 13.815511\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 107 [0/1196 (0%)]\tLoss: 12.088572\n",
      "Train Epoch: 107 [320/1196 (27%)]\tLoss: 15.542450\n",
      "Train Epoch: 107 [640/1196 (53%)]\tLoss: 18.996326\n",
      "Train Epoch: 107 [960/1196 (80%)]\tLoss: 15.542450\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 108 [0/1196 (0%)]\tLoss: 12.088572\n",
      "Train Epoch: 108 [320/1196 (27%)]\tLoss: 10.361633\n",
      "Train Epoch: 108 [640/1196 (53%)]\tLoss: 12.088572\n",
      "Train Epoch: 108 [960/1196 (80%)]\tLoss: 22.450205\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 109 [0/1196 (0%)]\tLoss: 13.815511\n",
      "Train Epoch: 109 [320/1196 (27%)]\tLoss: 17.269388\n",
      "Train Epoch: 109 [640/1196 (53%)]\tLoss: 13.815511\n",
      "Train Epoch: 109 [960/1196 (80%)]\tLoss: 10.361633\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 110 [0/1196 (0%)]\tLoss: 10.361633\n",
      "Train Epoch: 110 [320/1196 (27%)]\tLoss: 12.088572\n",
      "Train Epoch: 110 [640/1196 (53%)]\tLoss: 13.815511\n",
      "Train Epoch: 110 [960/1196 (80%)]\tLoss: 12.088572\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 111 [0/1196 (0%)]\tLoss: 13.815511\n",
      "Train Epoch: 111 [320/1196 (27%)]\tLoss: 12.088572\n",
      "Train Epoch: 111 [640/1196 (53%)]\tLoss: 17.269388\n",
      "Train Epoch: 111 [960/1196 (80%)]\tLoss: 10.361633\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 112 [0/1196 (0%)]\tLoss: 15.542450\n",
      "Train Epoch: 112 [320/1196 (27%)]\tLoss: 8.634694\n",
      "Train Epoch: 112 [640/1196 (53%)]\tLoss: 10.361633\n",
      "Train Epoch: 112 [960/1196 (80%)]\tLoss: 13.815511\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 113 [0/1196 (0%)]\tLoss: 15.542450\n",
      "Train Epoch: 113 [320/1196 (27%)]\tLoss: 15.542450\n",
      "Train Epoch: 113 [640/1196 (53%)]\tLoss: 10.361633\n",
      "Train Epoch: 113 [960/1196 (80%)]\tLoss: 15.542450\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 114 [0/1196 (0%)]\tLoss: 15.542450\n",
      "Train Epoch: 114 [320/1196 (27%)]\tLoss: 10.361633\n",
      "Train Epoch: 114 [640/1196 (53%)]\tLoss: 15.542450\n",
      "Train Epoch: 114 [960/1196 (80%)]\tLoss: 15.542450\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 115 [0/1196 (0%)]\tLoss: 15.542450\n",
      "Train Epoch: 115 [320/1196 (27%)]\tLoss: 12.088572\n",
      "Train Epoch: 115 [640/1196 (53%)]\tLoss: 13.815511\n",
      "Train Epoch: 115 [960/1196 (80%)]\tLoss: 8.634694\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 116 [0/1196 (0%)]\tLoss: 5.180817\n",
      "Train Epoch: 116 [320/1196 (27%)]\tLoss: 10.361633\n",
      "Train Epoch: 116 [640/1196 (53%)]\tLoss: 13.815511\n",
      "Train Epoch: 116 [960/1196 (80%)]\tLoss: 12.088572\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 117 [0/1196 (0%)]\tLoss: 13.815511\n",
      "Train Epoch: 117 [320/1196 (27%)]\tLoss: 8.634694\n",
      "Train Epoch: 117 [640/1196 (53%)]\tLoss: 10.361633\n",
      "Train Epoch: 117 [960/1196 (80%)]\tLoss: 8.634694\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 118 [0/1196 (0%)]\tLoss: 12.088572\n",
      "Train Epoch: 118 [320/1196 (27%)]\tLoss: 10.361633\n",
      "Train Epoch: 118 [640/1196 (53%)]\tLoss: 20.723267\n",
      "Train Epoch: 118 [960/1196 (80%)]\tLoss: 18.996326\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 119 [0/1196 (0%)]\tLoss: 18.996326\n",
      "Train Epoch: 119 [320/1196 (27%)]\tLoss: 15.542450\n",
      "Train Epoch: 119 [640/1196 (53%)]\tLoss: 15.542450\n",
      "Train Epoch: 119 [960/1196 (80%)]\tLoss: 10.361633\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 120 [0/1196 (0%)]\tLoss: 15.542450\n",
      "Train Epoch: 120 [320/1196 (27%)]\tLoss: 13.815511\n",
      "Train Epoch: 120 [640/1196 (53%)]\tLoss: 13.815511\n",
      "Train Epoch: 120 [960/1196 (80%)]\tLoss: 13.815511\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 121 [0/1196 (0%)]\tLoss: 17.269388\n",
      "Train Epoch: 121 [320/1196 (27%)]\tLoss: 15.542450\n",
      "Train Epoch: 121 [640/1196 (53%)]\tLoss: 10.361633\n",
      "Train Epoch: 121 [960/1196 (80%)]\tLoss: 15.542450\n",
      "\n",
      "Test set: Average loss: 13.8155, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 122 [0/1196 (0%)]\tLoss: 17.269388\n",
      "Train Epoch: 122 [320/1196 (27%)]\tLoss: 12.088572\n",
      "Train Epoch: 122 [640/1196 (53%)]\tLoss: 3.875933\n",
      "Train Epoch: 122 [960/1196 (80%)]\tLoss: 0.798605\n",
      "\n",
      "Test set: Average loss: 0.7034, Accuracy: 409/800 (51%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 123 [0/1196 (0%)]\tLoss: 0.693851\n",
      "Train Epoch: 123 [320/1196 (27%)]\tLoss: 0.688997\n",
      "Train Epoch: 123 [640/1196 (53%)]\tLoss: 0.996816\n",
      "Train Epoch: 123 [960/1196 (80%)]\tLoss: 0.694147\n",
      "\n",
      "Test set: Average loss: 0.7080, Accuracy: 387/800 (48%)\n",
      "\n",
      "Train Epoch: 124 [0/1196 (0%)]\tLoss: 0.706170\n",
      "Train Epoch: 124 [320/1196 (27%)]\tLoss: 0.733716\n",
      "Train Epoch: 124 [640/1196 (53%)]\tLoss: 0.711451\n",
      "Train Epoch: 124 [960/1196 (80%)]\tLoss: 0.675965\n",
      "\n",
      "Test set: Average loss: 0.8363, Accuracy: 385/800 (48%)\n",
      "\n",
      "Train Epoch: 125 [0/1196 (0%)]\tLoss: 0.730413\n",
      "Train Epoch: 125 [320/1196 (27%)]\tLoss: 0.695140\n",
      "Train Epoch: 125 [640/1196 (53%)]\tLoss: 0.734350\n",
      "Train Epoch: 125 [960/1196 (80%)]\tLoss: 0.693972\n",
      "\n",
      "Test set: Average loss: 0.7808, Accuracy: 395/800 (49%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 126 [0/1196 (0%)]\tLoss: 0.900119\n",
      "Train Epoch: 126 [320/1196 (27%)]\tLoss: 0.703088\n",
      "Train Epoch: 126 [640/1196 (53%)]\tLoss: 0.658244\n",
      "Train Epoch: 126 [960/1196 (80%)]\tLoss: 0.676014\n",
      "\n",
      "Test set: Average loss: 0.6877, Accuracy: 415/800 (52%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 127 [0/1196 (0%)]\tLoss: 0.666702\n",
      "Train Epoch: 127 [320/1196 (27%)]\tLoss: 0.707958\n",
      "Train Epoch: 127 [640/1196 (53%)]\tLoss: 0.690834\n",
      "Train Epoch: 127 [960/1196 (80%)]\tLoss: 0.710619\n",
      "\n",
      "Test set: Average loss: 0.6944, Accuracy: 396/800 (50%)\n",
      "\n",
      "Train Epoch: 128 [0/1196 (0%)]\tLoss: 0.638942\n",
      "Train Epoch: 128 [320/1196 (27%)]\tLoss: 0.814869\n",
      "Train Epoch: 128 [640/1196 (53%)]\tLoss: 0.758209\n",
      "Train Epoch: 128 [960/1196 (80%)]\tLoss: 0.674878\n",
      "\n",
      "Test set: Average loss: 0.6896, Accuracy: 389/800 (49%)\n",
      "\n",
      "Train Epoch: 129 [0/1196 (0%)]\tLoss: 0.656615\n",
      "Train Epoch: 129 [320/1196 (27%)]\tLoss: 0.687130\n",
      "Train Epoch: 129 [640/1196 (53%)]\tLoss: 0.683159\n",
      "Train Epoch: 129 [960/1196 (80%)]\tLoss: 0.667499\n",
      "\n",
      "Test set: Average loss: 0.6923, Accuracy: 403/800 (50%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 130 [0/1196 (0%)]\tLoss: 0.697376\n",
      "Train Epoch: 130 [320/1196 (27%)]\tLoss: 0.703923\n",
      "Train Epoch: 130 [640/1196 (53%)]\tLoss: 0.673862\n",
      "Train Epoch: 130 [960/1196 (80%)]\tLoss: 0.693199\n",
      "\n",
      "Test set: Average loss: 0.6945, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 131 [0/1196 (0%)]\tLoss: 0.721914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 131 [320/1196 (27%)]\tLoss: 0.710639\n",
      "Train Epoch: 131 [640/1196 (53%)]\tLoss: 0.687852\n",
      "Train Epoch: 131 [960/1196 (80%)]\tLoss: 0.693440\n",
      "\n",
      "Test set: Average loss: 0.6851, Accuracy: 426/800 (53%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 132 [0/1196 (0%)]\tLoss: 0.693093\n",
      "Train Epoch: 132 [320/1196 (27%)]\tLoss: 0.690795\n",
      "Train Epoch: 132 [640/1196 (53%)]\tLoss: 0.747775\n",
      "Train Epoch: 132 [960/1196 (80%)]\tLoss: 0.672767\n",
      "\n",
      "Test set: Average loss: 0.6948, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 133 [0/1196 (0%)]\tLoss: 0.692914\n",
      "Train Epoch: 133 [320/1196 (27%)]\tLoss: 0.691776\n",
      "Train Epoch: 133 [640/1196 (53%)]\tLoss: 0.689548\n",
      "Train Epoch: 133 [960/1196 (80%)]\tLoss: 0.725616\n",
      "\n",
      "Test set: Average loss: 0.7268, Accuracy: 377/800 (47%)\n",
      "\n",
      "Train Epoch: 134 [0/1196 (0%)]\tLoss: 0.736540\n",
      "Train Epoch: 134 [320/1196 (27%)]\tLoss: 0.600718\n",
      "Train Epoch: 134 [640/1196 (53%)]\tLoss: 0.652547\n",
      "Train Epoch: 134 [960/1196 (80%)]\tLoss: 0.679752\n",
      "\n",
      "Test set: Average loss: 0.6865, Accuracy: 466/800 (58%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 135 [0/1196 (0%)]\tLoss: 0.674841\n",
      "Train Epoch: 135 [320/1196 (27%)]\tLoss: 0.692438\n",
      "Train Epoch: 135 [640/1196 (53%)]\tLoss: 0.716765\n",
      "Train Epoch: 135 [960/1196 (80%)]\tLoss: 0.607956\n",
      "\n",
      "Test set: Average loss: 0.6964, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 136 [0/1196 (0%)]\tLoss: 0.712403\n",
      "Train Epoch: 136 [320/1196 (27%)]\tLoss: 0.684271\n",
      "Train Epoch: 136 [640/1196 (53%)]\tLoss: 0.700389\n",
      "Train Epoch: 136 [960/1196 (80%)]\tLoss: 0.692408\n",
      "\n",
      "Test set: Average loss: 0.6917, Accuracy: 403/800 (50%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 137 [0/1196 (0%)]\tLoss: 0.681007\n",
      "Train Epoch: 137 [320/1196 (27%)]\tLoss: 0.707880\n",
      "Train Epoch: 137 [640/1196 (53%)]\tLoss: 0.715692\n",
      "Train Epoch: 137 [960/1196 (80%)]\tLoss: 0.673655\n",
      "\n",
      "Test set: Average loss: 0.6873, Accuracy: 440/800 (55%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 138 [0/1196 (0%)]\tLoss: 0.694124\n",
      "Train Epoch: 138 [320/1196 (27%)]\tLoss: 0.686295\n",
      "Train Epoch: 138 [640/1196 (53%)]\tLoss: 0.699076\n",
      "Train Epoch: 138 [960/1196 (80%)]\tLoss: 0.692377\n",
      "\n",
      "Test set: Average loss: 0.6890, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 139 [0/1196 (0%)]\tLoss: 0.684871\n",
      "Train Epoch: 139 [320/1196 (27%)]\tLoss: 0.713850\n",
      "Train Epoch: 139 [640/1196 (53%)]\tLoss: 0.682380\n",
      "Train Epoch: 139 [960/1196 (80%)]\tLoss: 0.688958\n",
      "\n",
      "Test set: Average loss: 0.6940, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 140 [0/1196 (0%)]\tLoss: 0.692368\n",
      "Train Epoch: 140 [320/1196 (27%)]\tLoss: 0.701562\n",
      "Train Epoch: 140 [640/1196 (53%)]\tLoss: 0.693094\n",
      "Train Epoch: 140 [960/1196 (80%)]\tLoss: 0.725597\n",
      "\n",
      "Test set: Average loss: 0.6995, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 141 [0/1196 (0%)]\tLoss: 0.699478\n",
      "Train Epoch: 141 [320/1196 (27%)]\tLoss: 0.681146\n",
      "Train Epoch: 141 [640/1196 (53%)]\tLoss: 0.652701\n",
      "Train Epoch: 141 [960/1196 (80%)]\tLoss: 0.691867\n",
      "\n",
      "Test set: Average loss: 0.6854, Accuracy: 407/800 (51%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 142 [0/1196 (0%)]\tLoss: 0.666097\n",
      "Train Epoch: 142 [320/1196 (27%)]\tLoss: 0.740201\n",
      "Train Epoch: 142 [640/1196 (53%)]\tLoss: 0.729981\n",
      "Train Epoch: 142 [960/1196 (80%)]\tLoss: 0.670333\n",
      "\n",
      "Test set: Average loss: 0.6979, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 143 [0/1196 (0%)]\tLoss: 0.697325\n",
      "Train Epoch: 143 [320/1196 (27%)]\tLoss: 0.714534\n",
      "Train Epoch: 143 [640/1196 (53%)]\tLoss: 0.631819\n",
      "Train Epoch: 143 [960/1196 (80%)]\tLoss: 0.686482\n",
      "\n",
      "Test set: Average loss: 0.6809, Accuracy: 415/800 (52%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 144 [0/1196 (0%)]\tLoss: 0.698382\n",
      "Train Epoch: 144 [320/1196 (27%)]\tLoss: 0.716470\n",
      "Train Epoch: 144 [640/1196 (53%)]\tLoss: 0.693156\n",
      "Train Epoch: 144 [960/1196 (80%)]\tLoss: 0.697169\n",
      "\n",
      "Test set: Average loss: 0.6900, Accuracy: 415/800 (52%)\n",
      "\n",
      "Train Epoch: 145 [0/1196 (0%)]\tLoss: 0.703422\n",
      "Train Epoch: 145 [320/1196 (27%)]\tLoss: 0.656910\n",
      "Train Epoch: 145 [640/1196 (53%)]\tLoss: 0.673291\n",
      "Train Epoch: 145 [960/1196 (80%)]\tLoss: 0.658715\n",
      "\n",
      "Test set: Average loss: 0.6824, Accuracy: 451/800 (56%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 146 [0/1196 (0%)]\tLoss: 0.656440\n",
      "Train Epoch: 146 [320/1196 (27%)]\tLoss: 0.681842\n",
      "Train Epoch: 146 [640/1196 (53%)]\tLoss: 0.649723\n",
      "Train Epoch: 146 [960/1196 (80%)]\tLoss: 0.664678\n",
      "\n",
      "Test set: Average loss: 0.6819, Accuracy: 440/800 (55%)\n",
      "\n",
      "Train Epoch: 147 [0/1196 (0%)]\tLoss: 0.671674\n",
      "Train Epoch: 147 [320/1196 (27%)]\tLoss: 0.755547\n",
      "Train Epoch: 147 [640/1196 (53%)]\tLoss: 0.685456\n",
      "Train Epoch: 147 [960/1196 (80%)]\tLoss: 0.697265\n",
      "\n",
      "Test set: Average loss: 0.7008, Accuracy: 415/800 (52%)\n",
      "\n",
      "Train Epoch: 148 [0/1196 (0%)]\tLoss: 0.641542\n",
      "Train Epoch: 148 [320/1196 (27%)]\tLoss: 0.709676\n",
      "Train Epoch: 148 [640/1196 (53%)]\tLoss: 0.701993\n",
      "Train Epoch: 148 [960/1196 (80%)]\tLoss: 0.675737\n",
      "\n",
      "Test set: Average loss: 0.7003, Accuracy: 399/800 (50%)\n",
      "\n",
      "Train Epoch: 149 [0/1196 (0%)]\tLoss: 0.718928\n",
      "Train Epoch: 149 [320/1196 (27%)]\tLoss: 0.687054\n",
      "Train Epoch: 149 [640/1196 (53%)]\tLoss: 0.724684\n",
      "Train Epoch: 149 [960/1196 (80%)]\tLoss: 0.686980\n",
      "\n",
      "Test set: Average loss: 0.6850, Accuracy: 391/800 (49%)\n",
      "\n",
      "Train Epoch: 150 [0/1196 (0%)]\tLoss: 0.710309\n",
      "Train Epoch: 150 [320/1196 (27%)]\tLoss: 0.778545\n",
      "Train Epoch: 150 [640/1196 (53%)]\tLoss: 0.707273\n",
      "Train Epoch: 150 [960/1196 (80%)]\tLoss: 0.656422\n",
      "\n",
      "Test set: Average loss: 0.6837, Accuracy: 466/800 (58%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 151 [0/1196 (0%)]\tLoss: 0.670481\n",
      "Train Epoch: 151 [320/1196 (27%)]\tLoss: 0.661569\n",
      "Train Epoch: 151 [640/1196 (53%)]\tLoss: 0.685178\n",
      "Train Epoch: 151 [960/1196 (80%)]\tLoss: 0.691530\n",
      "\n",
      "Test set: Average loss: 0.6802, Accuracy: 415/800 (52%)\n",
      "\n",
      "Train Epoch: 152 [0/1196 (0%)]\tLoss: 0.672139\n",
      "Train Epoch: 152 [320/1196 (27%)]\tLoss: 0.693888\n",
      "Train Epoch: 152 [640/1196 (53%)]\tLoss: 0.705182\n",
      "Train Epoch: 152 [960/1196 (80%)]\tLoss: 0.679118\n",
      "\n",
      "Test set: Average loss: 1.1359, Accuracy: 407/800 (51%)\n",
      "\n",
      "Train Epoch: 153 [0/1196 (0%)]\tLoss: 0.670769\n",
      "Train Epoch: 153 [320/1196 (27%)]\tLoss: 0.686709\n",
      "Train Epoch: 153 [640/1196 (53%)]\tLoss: 0.770609\n",
      "Train Epoch: 153 [960/1196 (80%)]\tLoss: 0.709807\n",
      "\n",
      "Test set: Average loss: 0.7040, Accuracy: 405/800 (51%)\n",
      "\n",
      "Train Epoch: 154 [0/1196 (0%)]\tLoss: 0.633251\n",
      "Train Epoch: 154 [320/1196 (27%)]\tLoss: 0.652631\n",
      "Train Epoch: 154 [640/1196 (53%)]\tLoss: 0.749087\n",
      "Train Epoch: 154 [960/1196 (80%)]\tLoss: 0.687025\n",
      "\n",
      "Test set: Average loss: 0.6852, Accuracy: 403/800 (50%)\n",
      "\n",
      "Train Epoch: 155 [0/1196 (0%)]\tLoss: 0.670833\n",
      "Train Epoch: 155 [320/1196 (27%)]\tLoss: 0.718822\n",
      "Train Epoch: 155 [640/1196 (53%)]\tLoss: 0.688287\n",
      "Train Epoch: 155 [960/1196 (80%)]\tLoss: 0.682512\n",
      "\n",
      "Test set: Average loss: 0.6925, Accuracy: 397/800 (50%)\n",
      "\n",
      "Train Epoch: 156 [0/1196 (0%)]\tLoss: 0.594673\n",
      "Train Epoch: 156 [320/1196 (27%)]\tLoss: 0.657565\n",
      "Train Epoch: 156 [640/1196 (53%)]\tLoss: 0.586143\n",
      "Train Epoch: 156 [960/1196 (80%)]\tLoss: 0.681111\n",
      "\n",
      "Test set: Average loss: 0.6853, Accuracy: 462/800 (58%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 157 [0/1196 (0%)]\tLoss: 0.682637\n",
      "Train Epoch: 157 [320/1196 (27%)]\tLoss: 0.640748\n",
      "Train Epoch: 157 [640/1196 (53%)]\tLoss: 0.667920\n",
      "Train Epoch: 157 [960/1196 (80%)]\tLoss: 0.671934\n",
      "\n",
      "Test set: Average loss: 0.6914, Accuracy: 403/800 (50%)\n",
      "\n",
      "Train Epoch: 158 [0/1196 (0%)]\tLoss: 0.717227\n",
      "Train Epoch: 158 [320/1196 (27%)]\tLoss: 0.677863\n",
      "Train Epoch: 158 [640/1196 (53%)]\tLoss: 0.680741\n",
      "Train Epoch: 158 [960/1196 (80%)]\tLoss: 0.697104\n",
      "\n",
      "Test set: Average loss: 0.6821, Accuracy: 476/800 (60%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 159 [0/1196 (0%)]\tLoss: 0.679534\n",
      "Train Epoch: 159 [320/1196 (27%)]\tLoss: 0.709078\n",
      "Train Epoch: 159 [640/1196 (53%)]\tLoss: 0.683894\n",
      "Train Epoch: 159 [960/1196 (80%)]\tLoss: 0.697192\n",
      "\n",
      "Test set: Average loss: 0.7041, Accuracy: 399/800 (50%)\n",
      "\n",
      "Train Epoch: 160 [0/1196 (0%)]\tLoss: 0.619081\n",
      "Train Epoch: 160 [320/1196 (27%)]\tLoss: 0.759203\n",
      "Train Epoch: 160 [640/1196 (53%)]\tLoss: 0.726680\n",
      "Train Epoch: 160 [960/1196 (80%)]\tLoss: 0.731288\n",
      "\n",
      "Test set: Average loss: 0.6968, Accuracy: 406/800 (51%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 161 [0/1196 (0%)]\tLoss: 0.684988\n",
      "Train Epoch: 161 [320/1196 (27%)]\tLoss: 0.692940\n",
      "Train Epoch: 161 [640/1196 (53%)]\tLoss: 0.686525\n",
      "Train Epoch: 161 [960/1196 (80%)]\tLoss: 0.659615\n",
      "\n",
      "Test set: Average loss: 0.6878, Accuracy: 399/800 (50%)\n",
      "\n",
      "Train Epoch: 162 [0/1196 (0%)]\tLoss: 0.712033\n",
      "Train Epoch: 162 [320/1196 (27%)]\tLoss: 0.703800\n",
      "Train Epoch: 162 [640/1196 (53%)]\tLoss: 0.668930\n",
      "Train Epoch: 162 [960/1196 (80%)]\tLoss: 0.667541\n",
      "\n",
      "Test set: Average loss: 0.6733, Accuracy: 431/800 (54%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 163 [0/1196 (0%)]\tLoss: 0.618208\n",
      "Train Epoch: 163 [320/1196 (27%)]\tLoss: 0.726514\n",
      "Train Epoch: 163 [640/1196 (53%)]\tLoss: 0.670357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 163 [960/1196 (80%)]\tLoss: 0.723401\n",
      "\n",
      "Test set: Average loss: 0.6817, Accuracy: 406/800 (51%)\n",
      "\n",
      "Train Epoch: 164 [0/1196 (0%)]\tLoss: 0.740328\n",
      "Train Epoch: 164 [320/1196 (27%)]\tLoss: 0.708135\n",
      "Train Epoch: 164 [640/1196 (53%)]\tLoss: 0.706670\n",
      "Train Epoch: 164 [960/1196 (80%)]\tLoss: 0.631699\n",
      "\n",
      "Test set: Average loss: 0.6837, Accuracy: 447/800 (56%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 165 [0/1196 (0%)]\tLoss: 0.685693\n",
      "Train Epoch: 165 [320/1196 (27%)]\tLoss: 0.683216\n",
      "Train Epoch: 165 [640/1196 (53%)]\tLoss: 0.714080\n",
      "Train Epoch: 165 [960/1196 (80%)]\tLoss: 0.702355\n",
      "\n",
      "Test set: Average loss: 0.6787, Accuracy: 413/800 (52%)\n",
      "\n",
      "Train Epoch: 166 [0/1196 (0%)]\tLoss: 0.721542\n",
      "Train Epoch: 166 [320/1196 (27%)]\tLoss: 0.710551\n",
      "Train Epoch: 166 [640/1196 (53%)]\tLoss: 0.692725\n",
      "Train Epoch: 166 [960/1196 (80%)]\tLoss: 0.651529\n",
      "\n",
      "Test set: Average loss: 0.6859, Accuracy: 392/800 (49%)\n",
      "\n",
      "Train Epoch: 167 [0/1196 (0%)]\tLoss: 0.748814\n",
      "Train Epoch: 167 [320/1196 (27%)]\tLoss: 0.666627\n",
      "Train Epoch: 167 [640/1196 (53%)]\tLoss: 0.680844\n",
      "Train Epoch: 167 [960/1196 (80%)]\tLoss: 0.675916\n",
      "\n",
      "Test set: Average loss: 0.6789, Accuracy: 429/800 (54%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 168 [0/1196 (0%)]\tLoss: 0.655230\n",
      "Train Epoch: 168 [320/1196 (27%)]\tLoss: 0.760816\n",
      "Train Epoch: 168 [640/1196 (53%)]\tLoss: 0.689977\n",
      "Train Epoch: 168 [960/1196 (80%)]\tLoss: 0.694075\n",
      "\n",
      "Test set: Average loss: 0.6960, Accuracy: 407/800 (51%)\n",
      "\n",
      "Train Epoch: 169 [0/1196 (0%)]\tLoss: 0.678406\n",
      "Train Epoch: 169 [320/1196 (27%)]\tLoss: 0.635774\n",
      "Train Epoch: 169 [640/1196 (53%)]\tLoss: 0.677808\n",
      "Train Epoch: 169 [960/1196 (80%)]\tLoss: 0.647880\n",
      "\n",
      "Test set: Average loss: 0.6776, Accuracy: 450/800 (56%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 170 [0/1196 (0%)]\tLoss: 0.683950\n",
      "Train Epoch: 170 [320/1196 (27%)]\tLoss: 0.653065\n",
      "Train Epoch: 170 [640/1196 (53%)]\tLoss: 0.694190\n",
      "Train Epoch: 170 [960/1196 (80%)]\tLoss: 0.691990\n",
      "\n",
      "Test set: Average loss: 0.7130, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 171 [0/1196 (0%)]\tLoss: 0.737810\n",
      "Train Epoch: 171 [320/1196 (27%)]\tLoss: 0.775778\n",
      "Train Epoch: 171 [640/1196 (53%)]\tLoss: 0.796706\n",
      "Train Epoch: 171 [960/1196 (80%)]\tLoss: 0.701531\n",
      "\n",
      "Test set: Average loss: 0.6824, Accuracy: 464/800 (58%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 172 [0/1196 (0%)]\tLoss: 0.665058\n",
      "Train Epoch: 172 [320/1196 (27%)]\tLoss: 0.781888\n",
      "Train Epoch: 172 [640/1196 (53%)]\tLoss: 0.687080\n",
      "Train Epoch: 172 [960/1196 (80%)]\tLoss: 0.743233\n",
      "\n",
      "Test set: Average loss: 0.6842, Accuracy: 386/800 (48%)\n",
      "\n",
      "Train Epoch: 173 [0/1196 (0%)]\tLoss: 0.716255\n",
      "Train Epoch: 173 [320/1196 (27%)]\tLoss: 0.664429\n",
      "Train Epoch: 173 [640/1196 (53%)]\tLoss: 0.894778\n",
      "Train Epoch: 173 [960/1196 (80%)]\tLoss: 0.641315\n",
      "\n",
      "Test set: Average loss: 0.6977, Accuracy: 400/800 (50%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 174 [0/1196 (0%)]\tLoss: 0.671353\n",
      "Train Epoch: 174 [320/1196 (27%)]\tLoss: 0.700091\n",
      "Train Epoch: 174 [640/1196 (53%)]\tLoss: 0.699663\n",
      "Train Epoch: 174 [960/1196 (80%)]\tLoss: 0.693307\n",
      "\n",
      "Test set: Average loss: 0.6887, Accuracy: 445/800 (56%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 175 [0/1196 (0%)]\tLoss: 0.668575\n",
      "Train Epoch: 175 [320/1196 (27%)]\tLoss: 0.721020\n",
      "Train Epoch: 175 [640/1196 (53%)]\tLoss: 0.590934\n",
      "Train Epoch: 175 [960/1196 (80%)]\tLoss: 0.696227\n",
      "\n",
      "Test set: Average loss: 0.6928, Accuracy: 405/800 (51%)\n",
      "\n",
      "Train Epoch: 176 [0/1196 (0%)]\tLoss: 0.707237\n",
      "Train Epoch: 176 [320/1196 (27%)]\tLoss: 0.652961\n",
      "Train Epoch: 176 [640/1196 (53%)]\tLoss: 0.689479\n",
      "Train Epoch: 176 [960/1196 (80%)]\tLoss: 0.714757\n",
      "\n",
      "Test set: Average loss: 0.6872, Accuracy: 473/800 (59%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 177 [0/1196 (0%)]\tLoss: 0.662040\n",
      "Train Epoch: 177 [320/1196 (27%)]\tLoss: 0.674024\n",
      "Train Epoch: 177 [640/1196 (53%)]\tLoss: 0.647923\n",
      "Train Epoch: 177 [960/1196 (80%)]\tLoss: 0.716585\n",
      "\n",
      "Test set: Average loss: 0.7051, Accuracy: 477/800 (60%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 178 [0/1196 (0%)]\tLoss: 0.824464\n",
      "Train Epoch: 178 [320/1196 (27%)]\tLoss: 0.707847\n",
      "Train Epoch: 178 [640/1196 (53%)]\tLoss: 0.647709\n",
      "Train Epoch: 178 [960/1196 (80%)]\tLoss: 0.643284\n",
      "\n",
      "Test set: Average loss: 0.6804, Accuracy: 482/800 (60%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 179 [0/1196 (0%)]\tLoss: 0.672956\n",
      "Train Epoch: 179 [320/1196 (27%)]\tLoss: 0.658720\n",
      "Train Epoch: 179 [640/1196 (53%)]\tLoss: 0.564557\n",
      "Train Epoch: 179 [960/1196 (80%)]\tLoss: 0.686733\n",
      "\n",
      "Test set: Average loss: 0.7092, Accuracy: 401/800 (50%)\n",
      "\n",
      "Train Epoch: 180 [0/1196 (0%)]\tLoss: 0.755277\n",
      "Train Epoch: 180 [320/1196 (27%)]\tLoss: 0.684264\n",
      "Train Epoch: 180 [640/1196 (53%)]\tLoss: 0.781752\n",
      "Train Epoch: 180 [960/1196 (80%)]\tLoss: 0.673854\n",
      "\n",
      "Test set: Average loss: 0.7050, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 181 [0/1196 (0%)]\tLoss: 0.725013\n",
      "Train Epoch: 181 [320/1196 (27%)]\tLoss: 0.652143\n",
      "Train Epoch: 181 [640/1196 (53%)]\tLoss: 0.681608\n",
      "Train Epoch: 181 [960/1196 (80%)]\tLoss: 0.674096\n",
      "\n",
      "Test set: Average loss: 0.6810, Accuracy: 418/800 (52%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 182 [0/1196 (0%)]\tLoss: 0.650831\n",
      "Train Epoch: 182 [320/1196 (27%)]\tLoss: 0.749040\n",
      "Train Epoch: 182 [640/1196 (53%)]\tLoss: 0.726452\n",
      "Train Epoch: 182 [960/1196 (80%)]\tLoss: 0.681290\n",
      "\n",
      "Test set: Average loss: 0.6844, Accuracy: 430/800 (54%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 183 [0/1196 (0%)]\tLoss: 0.654894\n",
      "Train Epoch: 183 [320/1196 (27%)]\tLoss: 0.716800\n",
      "Train Epoch: 183 [640/1196 (53%)]\tLoss: 0.707178\n",
      "Train Epoch: 183 [960/1196 (80%)]\tLoss: 0.859276\n",
      "\n",
      "Test set: Average loss: 0.6806, Accuracy: 407/800 (51%)\n",
      "\n",
      "Train Epoch: 184 [0/1196 (0%)]\tLoss: 0.702908\n",
      "Train Epoch: 184 [320/1196 (27%)]\tLoss: 0.700472\n",
      "Train Epoch: 184 [640/1196 (53%)]\tLoss: 0.672843\n",
      "Train Epoch: 184 [960/1196 (80%)]\tLoss: 0.617025\n",
      "\n",
      "Test set: Average loss: 0.7658, Accuracy: 402/800 (50%)\n",
      "\n",
      "Train Epoch: 185 [0/1196 (0%)]\tLoss: 0.772097\n",
      "Train Epoch: 185 [320/1196 (27%)]\tLoss: 0.667750\n",
      "Train Epoch: 185 [640/1196 (53%)]\tLoss: 0.755040\n",
      "Train Epoch: 185 [960/1196 (80%)]\tLoss: 0.688577\n",
      "\n",
      "Test set: Average loss: 0.6870, Accuracy: 398/800 (50%)\n",
      "\n",
      "Train Epoch: 186 [0/1196 (0%)]\tLoss: 0.718339\n",
      "Train Epoch: 186 [320/1196 (27%)]\tLoss: 0.665874\n",
      "Train Epoch: 186 [640/1196 (53%)]\tLoss: 0.691960\n",
      "Train Epoch: 186 [960/1196 (80%)]\tLoss: 0.767992\n",
      "\n",
      "Test set: Average loss: 0.9841, Accuracy: 400/800 (50%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 187 [0/1196 (0%)]\tLoss: 1.634831\n",
      "Train Epoch: 187 [320/1196 (27%)]\tLoss: 0.644063\n",
      "Train Epoch: 187 [640/1196 (53%)]\tLoss: 0.792746\n",
      "Train Epoch: 187 [960/1196 (80%)]\tLoss: 0.683885\n",
      "\n",
      "Test set: Average loss: 0.6842, Accuracy: 464/800 (58%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 188 [0/1196 (0%)]\tLoss: 0.677633\n",
      "Train Epoch: 188 [320/1196 (27%)]\tLoss: 0.698466\n",
      "Train Epoch: 188 [640/1196 (53%)]\tLoss: 0.632106\n",
      "Train Epoch: 188 [960/1196 (80%)]\tLoss: 0.758466\n",
      "\n",
      "Test set: Average loss: 0.6815, Accuracy: 435/800 (54%)\n",
      "\n",
      "Train Epoch: 189 [0/1196 (0%)]\tLoss: 0.676119\n",
      "Train Epoch: 189 [320/1196 (27%)]\tLoss: 0.706269\n",
      "Train Epoch: 189 [640/1196 (53%)]\tLoss: 0.670945\n",
      "Train Epoch: 189 [960/1196 (80%)]\tLoss: 0.641642\n",
      "\n",
      "Test set: Average loss: 0.6765, Accuracy: 457/800 (57%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 190 [0/1196 (0%)]\tLoss: 0.665321\n",
      "Train Epoch: 190 [320/1196 (27%)]\tLoss: 0.713900\n",
      "Train Epoch: 190 [640/1196 (53%)]\tLoss: 0.658504\n",
      "Train Epoch: 190 [960/1196 (80%)]\tLoss: 0.661921\n",
      "\n",
      "Test set: Average loss: 0.6748, Accuracy: 426/800 (53%)\n",
      "\n",
      "Train Epoch: 191 [0/1196 (0%)]\tLoss: 0.669847\n",
      "Train Epoch: 191 [320/1196 (27%)]\tLoss: 0.602341\n",
      "Train Epoch: 191 [640/1196 (53%)]\tLoss: 0.686954\n",
      "Train Epoch: 191 [960/1196 (80%)]\tLoss: 0.715918\n",
      "\n",
      "Test set: Average loss: 0.6827, Accuracy: 429/800 (54%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 192 [0/1196 (0%)]\tLoss: 0.768957\n",
      "Train Epoch: 192 [320/1196 (27%)]\tLoss: 0.702588\n",
      "Train Epoch: 192 [640/1196 (53%)]\tLoss: 0.686998\n",
      "Train Epoch: 192 [960/1196 (80%)]\tLoss: 0.655664\n",
      "\n",
      "Test set: Average loss: 0.6952, Accuracy: 379/800 (47%)\n",
      "\n",
      "Train Epoch: 193 [0/1196 (0%)]\tLoss: 0.648801\n",
      "Train Epoch: 193 [320/1196 (27%)]\tLoss: 0.717756\n",
      "Train Epoch: 193 [640/1196 (53%)]\tLoss: 0.690853\n",
      "Train Epoch: 193 [960/1196 (80%)]\tLoss: 0.730823\n",
      "\n",
      "Test set: Average loss: 0.6867, Accuracy: 464/800 (58%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 194 [0/1196 (0%)]\tLoss: 0.661568\n",
      "Train Epoch: 194 [320/1196 (27%)]\tLoss: 0.693597\n",
      "Train Epoch: 194 [640/1196 (53%)]\tLoss: 0.602961\n",
      "Train Epoch: 194 [960/1196 (80%)]\tLoss: 0.749592\n",
      "\n",
      "Test set: Average loss: 0.6754, Accuracy: 439/800 (55%)\n",
      "\n",
      "Train Epoch: 195 [0/1196 (0%)]\tLoss: 0.690882\n",
      "Train Epoch: 195 [320/1196 (27%)]\tLoss: 0.687288\n",
      "Train Epoch: 195 [640/1196 (53%)]\tLoss: 0.686596\n",
      "Train Epoch: 195 [960/1196 (80%)]\tLoss: 0.615629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.6811, Accuracy: 417/800 (52%)\n",
      "\n",
      "Train Epoch: 196 [0/1196 (0%)]\tLoss: 0.666781\n",
      "Train Epoch: 196 [320/1196 (27%)]\tLoss: 0.589208\n",
      "Train Epoch: 196 [640/1196 (53%)]\tLoss: 0.555941\n",
      "Train Epoch: 196 [960/1196 (80%)]\tLoss: 1.167129\n",
      "\n",
      "Test set: Average loss: 0.6875, Accuracy: 449/800 (56%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 197 [0/1196 (0%)]\tLoss: 0.694419\n",
      "Train Epoch: 197 [320/1196 (27%)]\tLoss: 0.691432\n",
      "Train Epoch: 197 [640/1196 (53%)]\tLoss: 0.718660\n",
      "Train Epoch: 197 [960/1196 (80%)]\tLoss: 0.689005\n",
      "\n",
      "Test set: Average loss: 0.7126, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 198 [0/1196 (0%)]\tLoss: 0.687878\n",
      "Train Epoch: 198 [320/1196 (27%)]\tLoss: 0.608189\n",
      "Train Epoch: 198 [640/1196 (53%)]\tLoss: 0.686848\n",
      "Train Epoch: 198 [960/1196 (80%)]\tLoss: 0.708100\n",
      "\n",
      "Test set: Average loss: 0.6913, Accuracy: 379/800 (47%)\n",
      "\n",
      "Train Epoch: 199 [0/1196 (0%)]\tLoss: 0.667769\n",
      "Train Epoch: 199 [320/1196 (27%)]\tLoss: 0.703751\n",
      "Train Epoch: 199 [640/1196 (53%)]\tLoss: 0.644276\n",
      "Train Epoch: 199 [960/1196 (80%)]\tLoss: 0.694461\n",
      "\n",
      "Test set: Average loss: 0.7000, Accuracy: 400/800 (50%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 200 [0/1196 (0%)]\tLoss: 0.685558\n",
      "Train Epoch: 200 [320/1196 (27%)]\tLoss: 0.675303\n",
      "Train Epoch: 200 [640/1196 (53%)]\tLoss: 0.697394\n",
      "Train Epoch: 200 [960/1196 (80%)]\tLoss: 0.753988\n",
      "\n",
      "Test set: Average loss: 0.7011, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 201 [0/1196 (0%)]\tLoss: 0.748598\n",
      "Train Epoch: 201 [320/1196 (27%)]\tLoss: 0.685257\n",
      "Train Epoch: 201 [640/1196 (53%)]\tLoss: 0.686989\n",
      "Train Epoch: 201 [960/1196 (80%)]\tLoss: 0.697789\n",
      "\n",
      "Test set: Average loss: 0.6969, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 202 [0/1196 (0%)]\tLoss: 0.686025\n",
      "Train Epoch: 202 [320/1196 (27%)]\tLoss: 0.707224\n",
      "Train Epoch: 202 [640/1196 (53%)]\tLoss: 0.678606\n",
      "Train Epoch: 202 [960/1196 (80%)]\tLoss: 0.694870\n",
      "\n",
      "Test set: Average loss: 0.6976, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 203 [0/1196 (0%)]\tLoss: 0.694820\n",
      "Train Epoch: 203 [320/1196 (27%)]\tLoss: 0.653153\n",
      "Train Epoch: 203 [640/1196 (53%)]\tLoss: 0.676224\n",
      "Train Epoch: 203 [960/1196 (80%)]\tLoss: 0.606705\n",
      "\n",
      "Test set: Average loss: 0.7622, Accuracy: 406/800 (51%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 204 [0/1196 (0%)]\tLoss: 0.513780\n",
      "Train Epoch: 204 [320/1196 (27%)]\tLoss: 0.688517\n",
      "Train Epoch: 204 [640/1196 (53%)]\tLoss: 0.738705\n",
      "Train Epoch: 204 [960/1196 (80%)]\tLoss: 0.719760\n",
      "\n",
      "Test set: Average loss: 0.6961, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 205 [0/1196 (0%)]\tLoss: 0.679195\n",
      "Train Epoch: 205 [320/1196 (27%)]\tLoss: 0.695728\n",
      "Train Epoch: 205 [640/1196 (53%)]\tLoss: 0.704961\n",
      "Train Epoch: 205 [960/1196 (80%)]\tLoss: 0.676416\n",
      "\n",
      "Test set: Average loss: 0.6818, Accuracy: 432/800 (54%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 206 [0/1196 (0%)]\tLoss: 0.642495\n",
      "Train Epoch: 206 [320/1196 (27%)]\tLoss: 0.719726\n",
      "Train Epoch: 206 [640/1196 (53%)]\tLoss: 0.723037\n",
      "Train Epoch: 206 [960/1196 (80%)]\tLoss: 0.712233\n",
      "\n",
      "Test set: Average loss: 0.6952, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 207 [0/1196 (0%)]\tLoss: 0.727144\n",
      "Train Epoch: 207 [320/1196 (27%)]\tLoss: 0.694860\n",
      "Train Epoch: 207 [640/1196 (53%)]\tLoss: 0.680313\n",
      "Train Epoch: 207 [960/1196 (80%)]\tLoss: 0.709756\n",
      "\n",
      "Test set: Average loss: 0.6949, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 208 [0/1196 (0%)]\tLoss: 0.702293\n",
      "Train Epoch: 208 [320/1196 (27%)]\tLoss: 0.701065\n",
      "Train Epoch: 208 [640/1196 (53%)]\tLoss: 0.713919\n",
      "Train Epoch: 208 [960/1196 (80%)]\tLoss: 0.667213\n",
      "\n",
      "Test set: Average loss: 0.6941, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 209 [0/1196 (0%)]\tLoss: 0.711501\n",
      "Train Epoch: 209 [320/1196 (27%)]\tLoss: 0.704152\n",
      "Train Epoch: 209 [640/1196 (53%)]\tLoss: 0.826760\n",
      "Train Epoch: 209 [960/1196 (80%)]\tLoss: 0.685332\n",
      "\n",
      "Test set: Average loss: 0.6976, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 210 [0/1196 (0%)]\tLoss: 0.668583\n",
      "Train Epoch: 210 [320/1196 (27%)]\tLoss: 0.706466\n",
      "Train Epoch: 210 [640/1196 (53%)]\tLoss: 0.664029\n",
      "Train Epoch: 210 [960/1196 (80%)]\tLoss: 0.694419\n",
      "\n",
      "Test set: Average loss: 0.6888, Accuracy: 407/800 (51%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 211 [0/1196 (0%)]\tLoss: 0.678917\n",
      "Train Epoch: 211 [320/1196 (27%)]\tLoss: 0.777880\n",
      "Train Epoch: 211 [640/1196 (53%)]\tLoss: 0.706203\n",
      "Train Epoch: 211 [960/1196 (80%)]\tLoss: 0.703265\n",
      "\n",
      "Test set: Average loss: 0.6882, Accuracy: 390/800 (49%)\n",
      "\n",
      "Train Epoch: 212 [0/1196 (0%)]\tLoss: 0.692534\n",
      "Train Epoch: 212 [320/1196 (27%)]\tLoss: 0.625238\n",
      "Train Epoch: 212 [640/1196 (53%)]\tLoss: 0.685047\n",
      "Train Epoch: 212 [960/1196 (80%)]\tLoss: 0.706646\n",
      "\n",
      "Test set: Average loss: 0.6865, Accuracy: 415/800 (52%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 213 [0/1196 (0%)]\tLoss: 0.658350\n",
      "Train Epoch: 213 [320/1196 (27%)]\tLoss: 0.715804\n",
      "Train Epoch: 213 [640/1196 (53%)]\tLoss: 0.696679\n",
      "Train Epoch: 213 [960/1196 (80%)]\tLoss: 0.704362\n",
      "\n",
      "Test set: Average loss: 0.6957, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 214 [0/1196 (0%)]\tLoss: 0.650813\n",
      "Train Epoch: 214 [320/1196 (27%)]\tLoss: 0.706344\n",
      "Train Epoch: 214 [640/1196 (53%)]\tLoss: 0.671047\n",
      "Train Epoch: 214 [960/1196 (80%)]\tLoss: 0.723214\n",
      "\n",
      "Test set: Average loss: 0.6902, Accuracy: 449/800 (56%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 215 [0/1196 (0%)]\tLoss: 0.692403\n",
      "Train Epoch: 215 [320/1196 (27%)]\tLoss: 0.698942\n",
      "Train Epoch: 215 [640/1196 (53%)]\tLoss: 0.706173\n",
      "Train Epoch: 215 [960/1196 (80%)]\tLoss: 0.698617\n",
      "\n",
      "Test set: Average loss: 0.6825, Accuracy: 426/800 (53%)\n",
      "\n",
      "Train Epoch: 216 [0/1196 (0%)]\tLoss: 0.693912\n",
      "Train Epoch: 216 [320/1196 (27%)]\tLoss: 0.696137\n",
      "Train Epoch: 216 [640/1196 (53%)]\tLoss: 0.710909\n",
      "Train Epoch: 216 [960/1196 (80%)]\tLoss: 0.686932\n",
      "\n",
      "Test set: Average loss: 0.6953, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 217 [0/1196 (0%)]\tLoss: 0.703276\n",
      "Train Epoch: 217 [320/1196 (27%)]\tLoss: 0.693007\n",
      "Train Epoch: 217 [640/1196 (53%)]\tLoss: 0.716499\n",
      "Train Epoch: 217 [960/1196 (80%)]\tLoss: 0.715417\n",
      "\n",
      "Test set: Average loss: 0.6935, Accuracy: 392/800 (49%)\n",
      "\n",
      "Train Epoch: 218 [0/1196 (0%)]\tLoss: 0.720535\n",
      "Train Epoch: 218 [320/1196 (27%)]\tLoss: 0.705002\n",
      "Train Epoch: 218 [640/1196 (53%)]\tLoss: 0.901941\n",
      "Train Epoch: 218 [960/1196 (80%)]\tLoss: 0.837920\n",
      "\n",
      "Test set: Average loss: 0.6960, Accuracy: 401/800 (50%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 219 [0/1196 (0%)]\tLoss: 0.681637\n",
      "Train Epoch: 219 [320/1196 (27%)]\tLoss: 0.681621\n",
      "Train Epoch: 219 [640/1196 (53%)]\tLoss: 0.664120\n",
      "Train Epoch: 219 [960/1196 (80%)]\tLoss: 0.680960\n",
      "\n",
      "Test set: Average loss: 0.6941, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 220 [0/1196 (0%)]\tLoss: 0.711272\n",
      "Train Epoch: 220 [320/1196 (27%)]\tLoss: 0.660012\n",
      "Train Epoch: 220 [640/1196 (53%)]\tLoss: 0.709936\n",
      "Train Epoch: 220 [960/1196 (80%)]\tLoss: 0.637254\n",
      "\n",
      "Test set: Average loss: 0.6847, Accuracy: 417/800 (52%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 221 [0/1196 (0%)]\tLoss: 0.688184\n",
      "Train Epoch: 221 [320/1196 (27%)]\tLoss: 0.716950\n",
      "Train Epoch: 221 [640/1196 (53%)]\tLoss: 0.686371\n",
      "Train Epoch: 221 [960/1196 (80%)]\tLoss: 0.648567\n",
      "\n",
      "Test set: Average loss: 0.6867, Accuracy: 480/800 (60%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 222 [0/1196 (0%)]\tLoss: 0.675292\n",
      "Train Epoch: 222 [320/1196 (27%)]\tLoss: 0.695264\n",
      "Train Epoch: 222 [640/1196 (53%)]\tLoss: 0.692373\n",
      "Train Epoch: 222 [960/1196 (80%)]\tLoss: 0.657977\n",
      "\n",
      "Test set: Average loss: 0.6916, Accuracy: 404/800 (50%)\n",
      "\n",
      "Train Epoch: 223 [0/1196 (0%)]\tLoss: 0.695213\n",
      "Train Epoch: 223 [320/1196 (27%)]\tLoss: 0.703489\n",
      "Train Epoch: 223 [640/1196 (53%)]\tLoss: 0.720222\n",
      "Train Epoch: 223 [960/1196 (80%)]\tLoss: 0.705662\n",
      "\n",
      "Test set: Average loss: 0.6820, Accuracy: 430/800 (54%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 224 [0/1196 (0%)]\tLoss: 0.701350\n",
      "Train Epoch: 224 [320/1196 (27%)]\tLoss: 0.686645\n",
      "Train Epoch: 224 [640/1196 (53%)]\tLoss: 0.681031\n",
      "Train Epoch: 224 [960/1196 (80%)]\tLoss: 0.734448\n",
      "\n",
      "Test set: Average loss: 0.6928, Accuracy: 386/800 (48%)\n",
      "\n",
      "Train Epoch: 225 [0/1196 (0%)]\tLoss: 0.705510\n",
      "Train Epoch: 225 [320/1196 (27%)]\tLoss: 0.681760\n",
      "Train Epoch: 225 [640/1196 (53%)]\tLoss: 0.736676\n",
      "Train Epoch: 225 [960/1196 (80%)]\tLoss: 0.686676\n",
      "\n",
      "Test set: Average loss: 0.7261, Accuracy: 400/800 (50%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 226 [0/1196 (0%)]\tLoss: 0.792419\n",
      "Train Epoch: 226 [320/1196 (27%)]\tLoss: 0.699613\n",
      "Train Epoch: 226 [640/1196 (53%)]\tLoss: 0.689081\n",
      "Train Epoch: 226 [960/1196 (80%)]\tLoss: 0.794777\n",
      "\n",
      "Test set: Average loss: 0.6939, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 227 [0/1196 (0%)]\tLoss: 0.673061\n",
      "Train Epoch: 227 [320/1196 (27%)]\tLoss: 0.987170\n",
      "Train Epoch: 227 [640/1196 (53%)]\tLoss: 0.713745\n",
      "Train Epoch: 227 [960/1196 (80%)]\tLoss: 0.701324\n",
      "\n",
      "Test set: Average loss: 0.6849, Accuracy: 414/800 (52%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 228 [0/1196 (0%)]\tLoss: 0.680485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 228 [320/1196 (27%)]\tLoss: 0.706051\n",
      "Train Epoch: 228 [640/1196 (53%)]\tLoss: 0.740629\n",
      "Train Epoch: 228 [960/1196 (80%)]\tLoss: 0.707961\n",
      "\n",
      "Test set: Average loss: 0.6965, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 229 [0/1196 (0%)]\tLoss: 0.686389\n",
      "Train Epoch: 229 [320/1196 (27%)]\tLoss: 0.699225\n",
      "Train Epoch: 229 [640/1196 (53%)]\tLoss: 0.666942\n",
      "Train Epoch: 229 [960/1196 (80%)]\tLoss: 0.694267\n",
      "\n",
      "Test set: Average loss: 0.6913, Accuracy: 420/800 (52%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 230 [0/1196 (0%)]\tLoss: 0.691251\n",
      "Train Epoch: 230 [320/1196 (27%)]\tLoss: 0.672751\n",
      "Train Epoch: 230 [640/1196 (53%)]\tLoss: 0.739095\n",
      "Train Epoch: 230 [960/1196 (80%)]\tLoss: 0.958315\n",
      "\n",
      "Test set: Average loss: 0.6879, Accuracy: 453/800 (57%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 231 [0/1196 (0%)]\tLoss: 0.691652\n",
      "Train Epoch: 231 [320/1196 (27%)]\tLoss: 0.681269\n",
      "Train Epoch: 231 [640/1196 (53%)]\tLoss: 0.690131\n",
      "Train Epoch: 231 [960/1196 (80%)]\tLoss: 0.677650\n",
      "\n",
      "Test set: Average loss: 0.6884, Accuracy: 381/800 (48%)\n",
      "\n",
      "Train Epoch: 232 [0/1196 (0%)]\tLoss: 0.679402\n",
      "Train Epoch: 232 [320/1196 (27%)]\tLoss: 0.640574\n",
      "Train Epoch: 232 [640/1196 (53%)]\tLoss: 0.661047\n",
      "Train Epoch: 232 [960/1196 (80%)]\tLoss: 0.705003\n",
      "\n",
      "Test set: Average loss: 0.6914, Accuracy: 402/800 (50%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 233 [0/1196 (0%)]\tLoss: 0.637249\n",
      "Train Epoch: 233 [320/1196 (27%)]\tLoss: 0.797419\n",
      "Train Epoch: 233 [640/1196 (53%)]\tLoss: 0.705688\n",
      "Train Epoch: 233 [960/1196 (80%)]\tLoss: 0.678922\n",
      "\n",
      "Test set: Average loss: 0.6969, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 234 [0/1196 (0%)]\tLoss: 0.718892\n",
      "Train Epoch: 234 [320/1196 (27%)]\tLoss: 0.697195\n",
      "Train Epoch: 234 [640/1196 (53%)]\tLoss: 0.701877\n",
      "Train Epoch: 234 [960/1196 (80%)]\tLoss: 0.702429\n",
      "\n",
      "Test set: Average loss: 0.6893, Accuracy: 432/800 (54%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 235 [0/1196 (0%)]\tLoss: 0.696439\n",
      "Train Epoch: 235 [320/1196 (27%)]\tLoss: 0.633201\n",
      "Train Epoch: 235 [640/1196 (53%)]\tLoss: 0.683995\n",
      "Train Epoch: 235 [960/1196 (80%)]\tLoss: 0.868577\n",
      "\n",
      "Test set: Average loss: 0.6967, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 236 [0/1196 (0%)]\tLoss: 0.717702\n",
      "Train Epoch: 236 [320/1196 (27%)]\tLoss: 0.718807\n",
      "Train Epoch: 236 [640/1196 (53%)]\tLoss: 0.665975\n",
      "Train Epoch: 236 [960/1196 (80%)]\tLoss: 0.708413\n",
      "\n",
      "Test set: Average loss: 0.7073, Accuracy: 397/800 (50%)\n",
      "\n",
      "Train Epoch: 237 [0/1196 (0%)]\tLoss: 0.666691\n",
      "Train Epoch: 237 [320/1196 (27%)]\tLoss: 0.692518\n",
      "Train Epoch: 237 [640/1196 (53%)]\tLoss: 0.677685\n",
      "Train Epoch: 237 [960/1196 (80%)]\tLoss: 0.717576\n",
      "\n",
      "Test set: Average loss: 0.6922, Accuracy: 401/800 (50%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 238 [0/1196 (0%)]\tLoss: 0.686850\n",
      "Train Epoch: 238 [320/1196 (27%)]\tLoss: 0.697094\n",
      "Train Epoch: 238 [640/1196 (53%)]\tLoss: 0.679419\n",
      "Train Epoch: 238 [960/1196 (80%)]\tLoss: 0.685062\n",
      "\n",
      "Test set: Average loss: 0.6874, Accuracy: 430/800 (54%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 239 [0/1196 (0%)]\tLoss: 0.677901\n",
      "Train Epoch: 239 [320/1196 (27%)]\tLoss: 0.679512\n",
      "Train Epoch: 239 [640/1196 (53%)]\tLoss: 0.687879\n",
      "Train Epoch: 239 [960/1196 (80%)]\tLoss: 0.662372\n",
      "\n",
      "Test set: Average loss: 0.6896, Accuracy: 488/800 (61%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 240 [0/1196 (0%)]\tLoss: 0.696474\n",
      "Train Epoch: 240 [320/1196 (27%)]\tLoss: 0.694482\n",
      "Train Epoch: 240 [640/1196 (53%)]\tLoss: 0.678869\n",
      "Train Epoch: 240 [960/1196 (80%)]\tLoss: 0.697535\n",
      "\n",
      "Test set: Average loss: 0.6973, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 241 [0/1196 (0%)]\tLoss: 0.685901\n",
      "Train Epoch: 241 [320/1196 (27%)]\tLoss: 0.665209\n",
      "Train Epoch: 241 [640/1196 (53%)]\tLoss: 0.686470\n",
      "Train Epoch: 241 [960/1196 (80%)]\tLoss: 0.695586\n",
      "\n",
      "Test set: Average loss: 0.6952, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 242 [0/1196 (0%)]\tLoss: 0.679024\n",
      "Train Epoch: 242 [320/1196 (27%)]\tLoss: 0.694315\n",
      "Train Epoch: 242 [640/1196 (53%)]\tLoss: 0.692099\n",
      "Train Epoch: 242 [960/1196 (80%)]\tLoss: 0.688909\n",
      "\n",
      "Test set: Average loss: 0.6871, Accuracy: 404/800 (50%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 243 [0/1196 (0%)]\tLoss: 0.680580\n",
      "Train Epoch: 243 [320/1196 (27%)]\tLoss: 0.672816\n",
      "Train Epoch: 243 [640/1196 (53%)]\tLoss: 0.644609\n",
      "Train Epoch: 243 [960/1196 (80%)]\tLoss: 0.700930\n",
      "\n",
      "Test set: Average loss: 0.6948, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 244 [0/1196 (0%)]\tLoss: 0.687092\n",
      "Train Epoch: 244 [320/1196 (27%)]\tLoss: 0.680788\n",
      "Train Epoch: 244 [640/1196 (53%)]\tLoss: 0.665773\n",
      "Train Epoch: 244 [960/1196 (80%)]\tLoss: 0.653415\n",
      "\n",
      "Test set: Average loss: 0.6943, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 245 [0/1196 (0%)]\tLoss: 0.706632\n",
      "Train Epoch: 245 [320/1196 (27%)]\tLoss: 0.680999\n",
      "Train Epoch: 245 [640/1196 (53%)]\tLoss: 0.702574\n",
      "Train Epoch: 245 [960/1196 (80%)]\tLoss: 0.687311\n",
      "\n",
      "Test set: Average loss: 0.6885, Accuracy: 445/800 (56%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 246 [0/1196 (0%)]\tLoss: 0.702720\n",
      "Train Epoch: 246 [320/1196 (27%)]\tLoss: 0.733674\n",
      "Train Epoch: 246 [640/1196 (53%)]\tLoss: 0.685334\n",
      "Train Epoch: 246 [960/1196 (80%)]\tLoss: 0.687282\n",
      "\n",
      "Test set: Average loss: 0.6953, Accuracy: 399/800 (50%)\n",
      "\n",
      "Train Epoch: 247 [0/1196 (0%)]\tLoss: 0.696135\n",
      "Train Epoch: 247 [320/1196 (27%)]\tLoss: 0.635728\n",
      "Train Epoch: 247 [640/1196 (53%)]\tLoss: 0.683638\n",
      "Train Epoch: 247 [960/1196 (80%)]\tLoss: 0.697607\n",
      "\n",
      "Test set: Average loss: 0.6882, Accuracy: 459/800 (57%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 248 [0/1196 (0%)]\tLoss: 0.692981\n",
      "Train Epoch: 248 [320/1196 (27%)]\tLoss: 0.672231\n",
      "Train Epoch: 248 [640/1196 (53%)]\tLoss: 0.671696\n",
      "Train Epoch: 248 [960/1196 (80%)]\tLoss: 0.689557\n",
      "\n",
      "Test set: Average loss: 0.6845, Accuracy: 435/800 (54%)\n",
      "\n",
      "Train Epoch: 249 [0/1196 (0%)]\tLoss: 0.664723\n",
      "Train Epoch: 249 [320/1196 (27%)]\tLoss: 0.693429\n",
      "Train Epoch: 249 [640/1196 (53%)]\tLoss: 0.706499\n",
      "Train Epoch: 249 [960/1196 (80%)]\tLoss: 0.683884\n",
      "\n",
      "Test set: Average loss: 0.6885, Accuracy: 438/800 (55%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 250 [0/1196 (0%)]\tLoss: 0.690576\n",
      "Train Epoch: 250 [320/1196 (27%)]\tLoss: 0.713784\n",
      "Train Epoch: 250 [640/1196 (53%)]\tLoss: 0.717628\n",
      "Train Epoch: 250 [960/1196 (80%)]\tLoss: 0.716621\n",
      "\n",
      "Test set: Average loss: 0.6827, Accuracy: 424/800 (53%)\n",
      "\n",
      "Train Epoch: 251 [0/1196 (0%)]\tLoss: 0.692388\n",
      "Train Epoch: 251 [320/1196 (27%)]\tLoss: 0.671136\n",
      "Train Epoch: 251 [640/1196 (53%)]\tLoss: 0.739575\n",
      "Train Epoch: 251 [960/1196 (80%)]\tLoss: 0.780206\n",
      "\n",
      "Test set: Average loss: 0.6986, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 252 [0/1196 (0%)]\tLoss: 0.672117\n",
      "Train Epoch: 252 [320/1196 (27%)]\tLoss: 0.666342\n",
      "Train Epoch: 252 [640/1196 (53%)]\tLoss: 0.709670\n",
      "Train Epoch: 252 [960/1196 (80%)]\tLoss: 0.673437\n",
      "\n",
      "Test set: Average loss: 0.7442, Accuracy: 406/800 (51%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 253 [0/1196 (0%)]\tLoss: 0.887704\n",
      "Train Epoch: 253 [320/1196 (27%)]\tLoss: 0.634464\n",
      "Train Epoch: 253 [640/1196 (53%)]\tLoss: 0.664944\n",
      "Train Epoch: 253 [960/1196 (80%)]\tLoss: 0.751843\n",
      "\n",
      "Test set: Average loss: 0.6930, Accuracy: 398/800 (50%)\n",
      "\n",
      "Train Epoch: 254 [0/1196 (0%)]\tLoss: 0.743060\n",
      "Train Epoch: 254 [320/1196 (27%)]\tLoss: 0.653572\n",
      "Train Epoch: 254 [640/1196 (53%)]\tLoss: 0.684471\n",
      "Train Epoch: 254 [960/1196 (80%)]\tLoss: 0.675709\n",
      "\n",
      "Test set: Average loss: 0.6808, Accuracy: 428/800 (54%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 255 [0/1196 (0%)]\tLoss: 0.653242\n",
      "Train Epoch: 255 [320/1196 (27%)]\tLoss: 0.725604\n",
      "Train Epoch: 255 [640/1196 (53%)]\tLoss: 0.707282\n",
      "Train Epoch: 255 [960/1196 (80%)]\tLoss: 0.717972\n",
      "\n",
      "Test set: Average loss: 0.6959, Accuracy: 453/800 (57%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 256 [0/1196 (0%)]\tLoss: 0.646292\n",
      "Train Epoch: 256 [320/1196 (27%)]\tLoss: 0.685703\n",
      "Train Epoch: 256 [640/1196 (53%)]\tLoss: 0.690878\n",
      "Train Epoch: 256 [960/1196 (80%)]\tLoss: 0.705439\n",
      "\n",
      "Test set: Average loss: 0.6894, Accuracy: 418/800 (52%)\n",
      "\n",
      "Train Epoch: 257 [0/1196 (0%)]\tLoss: 0.721995\n",
      "Train Epoch: 257 [320/1196 (27%)]\tLoss: 0.676224\n",
      "Train Epoch: 257 [640/1196 (53%)]\tLoss: 0.687597\n",
      "Train Epoch: 257 [960/1196 (80%)]\tLoss: 0.710044\n",
      "\n",
      "Test set: Average loss: 0.7068, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 258 [0/1196 (0%)]\tLoss: 0.732206\n",
      "Train Epoch: 258 [320/1196 (27%)]\tLoss: 0.710459\n",
      "Train Epoch: 258 [640/1196 (53%)]\tLoss: 0.675624\n",
      "Train Epoch: 258 [960/1196 (80%)]\tLoss: 0.700587\n",
      "\n",
      "Test set: Average loss: 0.6916, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 259 [0/1196 (0%)]\tLoss: 0.720255\n",
      "Train Epoch: 259 [320/1196 (27%)]\tLoss: 0.672468\n",
      "Train Epoch: 259 [640/1196 (53%)]\tLoss: 0.649159\n",
      "Train Epoch: 259 [960/1196 (80%)]\tLoss: 0.744364\n",
      "\n",
      "Test set: Average loss: 0.7181, Accuracy: 403/800 (50%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 260 [0/1196 (0%)]\tLoss: 0.771248\n",
      "Train Epoch: 260 [320/1196 (27%)]\tLoss: 0.652941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 260 [640/1196 (53%)]\tLoss: 0.685019\n",
      "Train Epoch: 260 [960/1196 (80%)]\tLoss: 0.676252\n",
      "\n",
      "Test set: Average loss: 0.6787, Accuracy: 411/800 (51%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 261 [0/1196 (0%)]\tLoss: 0.706042\n",
      "Train Epoch: 261 [320/1196 (27%)]\tLoss: 0.696077\n",
      "Train Epoch: 261 [640/1196 (53%)]\tLoss: 0.731437\n",
      "Train Epoch: 261 [960/1196 (80%)]\tLoss: 0.699314\n",
      "\n",
      "Test set: Average loss: 0.6876, Accuracy: 473/800 (59%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 262 [0/1196 (0%)]\tLoss: 0.690573\n",
      "Train Epoch: 262 [320/1196 (27%)]\tLoss: 0.685515\n",
      "Train Epoch: 262 [640/1196 (53%)]\tLoss: 0.782370\n",
      "Train Epoch: 262 [960/1196 (80%)]\tLoss: 0.654954\n",
      "\n",
      "Test set: Average loss: 0.6947, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 263 [0/1196 (0%)]\tLoss: 0.702470\n",
      "Train Epoch: 263 [320/1196 (27%)]\tLoss: 0.658937\n",
      "Train Epoch: 263 [640/1196 (53%)]\tLoss: 0.692327\n",
      "Train Epoch: 263 [960/1196 (80%)]\tLoss: 0.724800\n",
      "\n",
      "Test set: Average loss: 0.6987, Accuracy: 394/800 (49%)\n",
      "\n",
      "Train Epoch: 264 [0/1196 (0%)]\tLoss: 0.708423\n",
      "Train Epoch: 264 [320/1196 (27%)]\tLoss: 0.664337\n",
      "Train Epoch: 264 [640/1196 (53%)]\tLoss: 0.646172\n",
      "Train Epoch: 264 [960/1196 (80%)]\tLoss: 0.702391\n",
      "\n",
      "Test set: Average loss: 0.6942, Accuracy: 400/800 (50%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 265 [0/1196 (0%)]\tLoss: 0.666382\n",
      "Train Epoch: 265 [320/1196 (27%)]\tLoss: 0.676062\n",
      "Train Epoch: 265 [640/1196 (53%)]\tLoss: 0.680321\n",
      "Train Epoch: 265 [960/1196 (80%)]\tLoss: 0.685887\n",
      "\n",
      "Test set: Average loss: 0.6832, Accuracy: 494/800 (62%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 266 [0/1196 (0%)]\tLoss: 0.682093\n",
      "Train Epoch: 266 [320/1196 (27%)]\tLoss: 0.704058\n",
      "Train Epoch: 266 [640/1196 (53%)]\tLoss: 0.706955\n",
      "Train Epoch: 266 [960/1196 (80%)]\tLoss: 0.697699\n",
      "\n",
      "Test set: Average loss: 0.6818, Accuracy: 470/800 (59%)\n",
      "\n",
      "Train Epoch: 267 [0/1196 (0%)]\tLoss: 0.697287\n",
      "Train Epoch: 267 [320/1196 (27%)]\tLoss: 0.926099\n",
      "Train Epoch: 267 [640/1196 (53%)]\tLoss: 0.695273\n",
      "Train Epoch: 267 [960/1196 (80%)]\tLoss: 0.756094\n",
      "\n",
      "Test set: Average loss: 0.7260, Accuracy: 436/800 (54%)\n",
      "\n",
      "Train Epoch: 268 [0/1196 (0%)]\tLoss: 1.227363\n",
      "Train Epoch: 268 [320/1196 (27%)]\tLoss: 0.711328\n",
      "Train Epoch: 268 [640/1196 (53%)]\tLoss: 0.747343\n",
      "Train Epoch: 268 [960/1196 (80%)]\tLoss: 0.752126\n",
      "\n",
      "Test set: Average loss: 0.6912, Accuracy: 442/800 (55%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 269 [0/1196 (0%)]\tLoss: 0.716007\n",
      "Train Epoch: 269 [320/1196 (27%)]\tLoss: 0.704052\n",
      "Train Epoch: 269 [640/1196 (53%)]\tLoss: 0.714719\n",
      "Train Epoch: 269 [960/1196 (80%)]\tLoss: 0.660246\n",
      "\n",
      "Test set: Average loss: 0.6916, Accuracy: 407/800 (51%)\n",
      "\n",
      "Train Epoch: 270 [0/1196 (0%)]\tLoss: 0.712738\n",
      "Train Epoch: 270 [320/1196 (27%)]\tLoss: 0.698386\n",
      "Train Epoch: 270 [640/1196 (53%)]\tLoss: 0.710350\n",
      "Train Epoch: 270 [960/1196 (80%)]\tLoss: 0.677662\n",
      "\n",
      "Test set: Average loss: 0.6907, Accuracy: 432/800 (54%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 271 [0/1196 (0%)]\tLoss: 0.697541\n",
      "Train Epoch: 271 [320/1196 (27%)]\tLoss: 0.666454\n",
      "Train Epoch: 271 [640/1196 (53%)]\tLoss: 0.698815\n",
      "Train Epoch: 271 [960/1196 (80%)]\tLoss: 0.713070\n",
      "\n",
      "Test set: Average loss: 0.6983, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 272 [0/1196 (0%)]\tLoss: 0.724170\n",
      "Train Epoch: 272 [320/1196 (27%)]\tLoss: 0.690869\n",
      "Train Epoch: 272 [640/1196 (53%)]\tLoss: 0.677655\n",
      "Train Epoch: 272 [960/1196 (80%)]\tLoss: 0.713018\n",
      "\n",
      "Test set: Average loss: 0.6881, Accuracy: 473/800 (59%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 273 [0/1196 (0%)]\tLoss: 0.680792\n",
      "Train Epoch: 273 [320/1196 (27%)]\tLoss: 0.671776\n",
      "Train Epoch: 273 [640/1196 (53%)]\tLoss: 0.731465\n",
      "Train Epoch: 273 [960/1196 (80%)]\tLoss: 0.685555\n",
      "\n",
      "Test set: Average loss: 0.6878, Accuracy: 489/800 (61%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 274 [0/1196 (0%)]\tLoss: 0.690995\n",
      "Train Epoch: 274 [320/1196 (27%)]\tLoss: 0.688722\n",
      "Train Epoch: 274 [640/1196 (53%)]\tLoss: 0.765961\n",
      "Train Epoch: 274 [960/1196 (80%)]\tLoss: 0.708828\n",
      "\n",
      "Test set: Average loss: 0.6876, Accuracy: 489/800 (61%)\n",
      "\n",
      "Train Epoch: 275 [0/1196 (0%)]\tLoss: 0.696011\n",
      "Train Epoch: 275 [320/1196 (27%)]\tLoss: 0.676702\n",
      "Train Epoch: 275 [640/1196 (53%)]\tLoss: 0.675964\n",
      "Train Epoch: 275 [960/1196 (80%)]\tLoss: 0.656410\n",
      "\n",
      "Test set: Average loss: 0.6987, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 276 [0/1196 (0%)]\tLoss: 0.711904\n",
      "Train Epoch: 276 [320/1196 (27%)]\tLoss: 0.683756\n",
      "Train Epoch: 276 [640/1196 (53%)]\tLoss: 0.688770\n",
      "Train Epoch: 276 [960/1196 (80%)]\tLoss: 0.685043\n",
      "\n",
      "Test set: Average loss: 0.6863, Accuracy: 417/800 (52%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 277 [0/1196 (0%)]\tLoss: 0.674958\n",
      "Train Epoch: 277 [320/1196 (27%)]\tLoss: 0.682980\n",
      "Train Epoch: 277 [640/1196 (53%)]\tLoss: 0.704264\n",
      "Train Epoch: 277 [960/1196 (80%)]\tLoss: 0.722768\n",
      "\n",
      "Test set: Average loss: 0.6984, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 278 [0/1196 (0%)]\tLoss: 0.711179\n",
      "Train Epoch: 278 [320/1196 (27%)]\tLoss: 0.686464\n",
      "Train Epoch: 278 [640/1196 (53%)]\tLoss: 0.680418\n",
      "Train Epoch: 278 [960/1196 (80%)]\tLoss: 0.683986\n",
      "\n",
      "Test set: Average loss: 0.6893, Accuracy: 401/800 (50%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 279 [0/1196 (0%)]\tLoss: 0.696851\n",
      "Train Epoch: 279 [320/1196 (27%)]\tLoss: 0.676207\n",
      "Train Epoch: 279 [640/1196 (53%)]\tLoss: 0.704882\n",
      "Train Epoch: 279 [960/1196 (80%)]\tLoss: 0.662397\n",
      "\n",
      "Test set: Average loss: 0.6964, Accuracy: 400/800 (50%)\n",
      "\n",
      "Train Epoch: 280 [0/1196 (0%)]\tLoss: 0.708783\n",
      "Train Epoch: 280 [320/1196 (27%)]\tLoss: 0.713281\n",
      "Train Epoch: 280 [640/1196 (53%)]\tLoss: 0.708470\n",
      "Train Epoch: 280 [960/1196 (80%)]\tLoss: 0.669232\n",
      "\n",
      "Test set: Average loss: 0.6842, Accuracy: 398/800 (50%)\n",
      "\n",
      "Train Epoch: 281 [0/1196 (0%)]\tLoss: 0.725577\n",
      "Train Epoch: 281 [320/1196 (27%)]\tLoss: 0.680645\n",
      "Train Epoch: 281 [640/1196 (53%)]\tLoss: 0.632407\n",
      "Train Epoch: 281 [960/1196 (80%)]\tLoss: 0.672367\n",
      "\n",
      "Test set: Average loss: 0.6978, Accuracy: 400/800 (50%)\n",
      "\n",
      "Saving..\n",
      "Train Epoch: 282 [0/1196 (0%)]\tLoss: 0.734582\n",
      "Train Epoch: 282 [320/1196 (27%)]\tLoss: 0.713736\n",
      "Train Epoch: 282 [640/1196 (53%)]\tLoss: 0.694475\n",
      "Train Epoch: 282 [960/1196 (80%)]\tLoss: 0.727551\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, 500):\n",
    "        train(net, train_loader, optimizer, epoch,device)\n",
    "        test(net, test_loader,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('==> Resuming from checkpoint..')\n",
    "# assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "# checkpoint = torch.load('./checkpoint/ckpt.t7')\n",
    "# net.load_state_dict(checkpoint['net'])\n",
    "# best_acc = checkpoint['acc']\n",
    "# start_epoch = checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Evaluate Accuracy\n",
    "print('Training Loss:', train_loss[-1])\n",
    "print('Training Accuracy:', train_accu[-1])\n",
    "print()\n",
    "print('Test Loss:', np.mean(val_loss))\n",
    "print('Testing Accuracy:', np.max(test_accu))\n",
    "print()\n",
    "\n",
    "plt.plot(train_loss,'r', label='Training Loss')\n",
    "plt.plot(val_loss,'b', label='Testing Loss')\n",
    "plt.title('Test Loss ' + str(val_loss[-1]))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(train_accu,'r', label='Training accuracy')\n",
    "plt.plot(test_accu,'b', label='Testing accuracy')\n",
    "plt.title('Test Accuracy : '+ str(np.max(test_accu)))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferences\n",
    "* It is clear from the abive graph that, there is overfitting in the network.\n",
    "* I tried different menthods like changing dropouts and actiavtion functions to do address this.\n",
    "* This did not help as, even though the overfitting decreased the final test accuracy always decreased.\n",
    "* Adam gave beteer performance than SGD.\n",
    "* The haphazard motion of both error and accuracy is due to the random shuffling of data in minibatches after each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incorrect Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err=[]\n",
    "ind=[]\n",
    "predictedlabel=[]\n",
    "targetlabel=[]\n",
    "classlabels = ['airplane', 'automobile', 'bird', 'cat' , 'deer' , 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "n = 6   # Number of False predictions to output\n",
    "\n",
    "vis_loader = torch.utils.data.DataLoader(testset, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "# vis_loader = torch.utils.data.DataLoader(\n",
    "#     FlowerLoader(x_test, y_test, transforms.Compose([\n",
    "#         transforms.ToPILImage(),\n",
    "#         transforms.ToTensor(),\n",
    "#         normalize,\n",
    "#     ])), shuffle=False)\n",
    "\n",
    "for data, target in vis_loader:\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    #==== Getting the Prediction======\n",
    "    output = net(data)\n",
    "    #===== Calculating the Loss=========\n",
    "    test_loss = criterion(output, target)\n",
    "    err.append(test_loss.item())\n",
    "    # Checking what predictions are correct========\n",
    "    pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "    predictedlabel.append(pred.item())\n",
    "    targetlabel.append(target.item())\n",
    "    neg = ~pred.eq(target.view_as(pred))\n",
    "    ind.append(neg.item())\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======= Plotting Incorrect=======\n",
    "ind,err,predictedlabel,targetlabel =np.asarray(ind), np.asarray(err), np.asarray(predictedlabel),np.asarray(targetlabel)\n",
    "incorrecterrors=ind*err\n",
    "maxerrorind = np.argpartition(incorrecterrors, -n)[-n:]\n",
    "\n",
    "nrows,ncols = 2 ,3\n",
    "fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n",
    "num = 0\n",
    "for row in range(nrows):\n",
    "    for col in range(ncols):\n",
    "        ax[row,col].imshow(x_test[maxerrorind[num]])\n",
    "        ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(classlabels[predictedlabel[maxerrorind[num]]],\n",
    "                                                                              classlabels[targetlabel[maxerrorind[num]]]))\n",
    "        num = num+1\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======= Plotting Correct=======\n",
    "\n",
    "ind,err,predictedlabel,targetlabel =np.asarray(~ind), np.asarray(err), np.asarray(predictedlabel),np.asarray(targetlabel)\n",
    "incorrecterrors=ind*err\n",
    "maxerrorind = np.argpartition(incorrecterrors, -n)[-n:]\n",
    "\n",
    "nrows,ncols = 2 ,3\n",
    "fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n",
    "num =  0\n",
    "for row in range(nrows):\n",
    "    for col in range(ncols):\n",
    "        ax[row,col].imshow(x_test[maxerrorind[num]])\n",
    "        ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(classlabels[predictedlabel[maxerrorind[num]]],\n",
    "                                                                               classlabels[targetlabel[maxerrorind[num]]]))\n",
    "        num = num + 1\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Implementing using Local Binary Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC  \n",
    "import argparse\n",
    "import cv2\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from keras.datasets import cifar10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numPoints = 48\n",
    "radius = 1\n",
    "def describe(image, eps=1e-7):\n",
    "# compute the Local Binary Pattern representation\n",
    "# of the image, and then use the LBP representation\n",
    "# to build the histogram of patterns\n",
    "    lbp = feature.local_binary_pattern(image,numPoints,radius, method=\"uniform\")\n",
    "    (hist, _) = np.histogram(lbp.ravel(),bins=np.arange(0, numPoints + 3), range=(0, numPoints + 2)) \n",
    "# # normalize the histogram\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + eps)\n",
    "    # return the histogram of Local Binary Patterns\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "for i in range(0,x_train.shape[0]):\n",
    "    img = x_train[i]\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    hist = describe(gray)\n",
    "    labels.append(y_train[i])\n",
    "    data.append(hist)\n",
    "#     print(hist.shape)\n",
    "#     break\n",
    "# np.save('train_data.npy',data)\n",
    "# np.save('train_label.npy',labels)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a Linear SVM on the data\n",
    "# data = np.load('train_data.npy')\n",
    "# labels = np.load('train_label.npy')   \n",
    "svclassifier = LinearSVC(tol=1e-5)  \n",
    "h = svclassifier.fit(data, labels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = [] \n",
    "predictlabel=[]\n",
    "# loop over the testing images\n",
    "for i in range(0,x_test.shape[0]):\n",
    "    img = x_test[i]\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    hist = describe(gray)\n",
    "    prediction = h.predict(hist.reshape(1, -1))\n",
    "    acc.append(prediction == y_test[i])\n",
    "    predictlabel.append(prediction)\n",
    "acc = np.asarray(acc)*1    \n",
    "print('Test Accuracy = ' + str(np.mean(acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting Training VS Epoch Plots\n",
    "# Function taken from (Kaggle) https://www.kaggle.com/paul92s/linear-svc-classifier#\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, x1, y1, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, x1, y1, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "# title = \"Learning Curves ( Linear SVM)\"\n",
    "# cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "# plot_learning_curve(h, title, data, labels, cv=cv)\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorrect Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index =  np.where(acc == 0)[0]\n",
    "classlabels=np.asarray(classlabels) \n",
    "#======= Plotting Incorrect=======\n",
    "nrows,ncols = 2 ,3\n",
    "fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n",
    "num = 0\n",
    "for row in range(nrows):\n",
    "    for col in range(ncols):\n",
    "        ax[row,col].imshow(x_test[index[num]])\n",
    "        ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(classlabels[predictlabel[index[num]].astype(int)],\n",
    "                                                                              classlabels[y_test[index[num]].astype(int)]))\n",
    "        num = num+1\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posindex =  np.where(acc == 1)[0]\n",
    "#======= Plotting Incorrect=======\n",
    "nrows,ncols = 2 ,3\n",
    "fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n",
    "num = 0\n",
    "for row in range(nrows):\n",
    "    for col in range(ncols):\n",
    "        ax[row,col].imshow(x_test[posindex[num]])\n",
    "        ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(classlabels[predictlabel[posindex[num]].astype(int)],\n",
    "                                                                              classlabels[y_test[posindex[num]].astype(int)]))\n",
    "        num = num+1\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
