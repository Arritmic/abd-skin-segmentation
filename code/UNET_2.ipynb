{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set some parameters\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "seed = 42\n",
    "random.seed = seed\n",
    "np.random.seed = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_comp(act, pr): #Takes as input 2D masks and 2D predictions\n",
    "    c = act == pr #acc\n",
    "    d = act & pr #true negative\n",
    "    e = act | pr #true positive\n",
    "    neg = act.sum()\n",
    "    pos = (IMG_WIDTH*IMG_HEIGHT)-act.sum()\n",
    "    \n",
    "    TN = round(float(d.sum())/neg,6)\n",
    "    FN = round(float(pr.sum()-TN)/neg,6)\n",
    "    TP = round(float((IMG_WIDTH*IMG_HEIGHT)-e.sum())/pos,6)\n",
    "    FP = round(float(e.sum()-pr.sum())/pos,6)\n",
    "    acc = round(float(c.sum())/(IMG_WIDTH*IMG_HEIGHT),6)\n",
    "    #acc2 = float(TP+TN)/(TP+TN+FP+FN)\n",
    "    \n",
    "    return (acc, TN, FN, TP, FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class for extracting time per epoch\n",
    "class TimingCallback(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "\n",
    "cb = TimingCallback()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define IoU metric\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Training Data (Original+Mask)\n",
    "# Dataset 1: HGR\n",
    "TRAIN_PATH1 = ['/Users/lydiazoghbi/Desktop/Skin Detection/Segmentation/Skin_Datasets/Dataset1_HGR/original_images/']\n",
    "MASK_PATH1 = ['/Users/lydiazoghbi/Desktop/Skin Detection/Segmentation/Skin_Datasets/Dataset1_HGR/skin_masks/']\n",
    "train_id1 = next(os.walk(TRAIN_PATH1[0]))[2]\n",
    "mask_ids1 = next(os.walk(MASK_PATH1[0]))[2]\n",
    "train_id1.sort()\n",
    "train_ids1 = train_id1[1:] #In case some weird crap .DStore file popped up\n",
    "mask_ids1.sort()\n",
    "TRAIN_PATH1 = TRAIN_PATH1*len(train_ids1)\n",
    "MASK_PATH1 = MASK_PATH1*len(train_ids1)\n",
    "\n",
    "# Dataset 4: Pratheepan\n",
    "TRAIN_PATH2 = ['/Users/lydiazoghbi/Desktop/Skin Detection/Segmentation/Skin_Datasets/Dataset4_Pratheepan/original_images/']\n",
    "MASK_PATH2 = ['/Users/lydiazoghbi/Desktop/Skin Detection/Segmentation/Skin_Datasets/Dataset4_Pratheepan/skin_masks/']\n",
    "train_ids2 = next(os.walk(TRAIN_PATH2[0]))[2]\n",
    "mask_ids2 = next(os.walk(MASK_PATH2[0]))[2]\n",
    "train_ids2.sort()\n",
    "mask_ids2.sort()\n",
    "TRAIN_PATH2 = TRAIN_PATH2*len(train_ids2)\n",
    "MASK_PATH2 = MASK_PATH2*len(train_ids2)\n",
    "\n",
    "# Dataset 5: VDM\n",
    "TRAIN_PATH3 = ['/Users/lydiazoghbi/Desktop/Skin Detection/Segmentation/Skin_Datasets/Dataset5_VDM/original_images/']\n",
    "MASK_PATH3 = ['/Users/lydiazoghbi/Desktop/Skin Detection/Segmentation/Skin_Datasets/Dataset5_VDM/skin_masks/']\n",
    "train_id3 = next(os.walk(TRAIN_PATH3[0]))[2]\n",
    "mask_id3 = next(os.walk(MASK_PATH3[0]))[2]\n",
    "train_id3.sort()\n",
    "mask_id3.sort()\n",
    "train_ids3 = train_id3[1:]\n",
    "mask_ids3 = mask_id3[1:]\n",
    "TRAIN_PATH3 = TRAIN_PATH3*len(train_ids3)\n",
    "MASK_PATH3 = MASK_PATH3*len(train_ids3)\n",
    "\n",
    "# Dataset 5: SFA\n",
    "TRAIN_PATH4 = ['/Users/lydiazoghbi/Desktop/Skin Detection/Segmentation/Skin_Datasets/Dataset6_SFA/original_images/']\n",
    "MASK_PATH4 = ['/Users/lydiazoghbi/Desktop/Skin Detection/Segmentation/Skin_Datasets/Dataset6_SFA/skin_masks/']\n",
    "train_ids4 = next(os.walk(TRAIN_PATH4[0]))[2]\n",
    "mask_ids4 = next(os.walk(MASK_PATH4[0]))[2]\n",
    "train_ids4.sort()\n",
    "mask_ids4.sort()\n",
    "TRAIN_PATH4 = TRAIN_PATH4*len(train_ids4)\n",
    "MASK_PATH4 = MASK_PATH4*len(train_ids4)\n",
    "\n",
    "# Combine everything\n",
    "TRAIN_PATH = np.concatenate((TRAIN_PATH1,TRAIN_PATH2,TRAIN_PATH3,TRAIN_PATH4))\n",
    "MASK_PATH = np.concatenate((MASK_PATH1,MASK_PATH2,MASK_PATH3,MASK_PATH4))\n",
    "train_ids = np.concatenate((train_ids1,train_ids2,train_ids3,train_ids4))\n",
    "mask_ids = np.concatenate((mask_ids1,mask_ids2,mask_ids3,mask_ids4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and resize train images and masks\n",
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = TRAIN_PATH[n] + id_\n",
    "    img = imread(path)[:,:,:IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_train[n] = img\n",
    "\n",
    "for n, id_ in tqdm(enumerate(mask_ids), total=len(mask_ids)):\n",
    "    path = MASK_PATH[n] + id_\n",
    "    img = imread(path)\n",
    "    if n in range(899,977):\n",
    "        img = img[:,:,1]\n",
    "    img = np.expand_dims(resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
    "                                      preserve_range=True), axis=-1)\n",
    "    Y_train[n] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if training masks match ground truth\n",
    "ix = random.randint(0, len(train_ids))\n",
    "imshow(X_train[ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if training data looks all right\n",
    "ix = random.randint(0, len(train_ids))\n",
    "imshow(X_train[ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build U-Net model\n",
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "s = Lambda(lambda x: x / 255) (inputs)\n",
    "\n",
    "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n",
    "c1 = Dropout(0.1) (c1)\n",
    "c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
    "c2 = Dropout(0.1) (c2)\n",
    "c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
    "c3 = Dropout(0.2) (c3)\n",
    "c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
    "c4 = Dropout(0.2) (c4)\n",
    "c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
    "c5 = Dropout(0.3) (c5)\n",
    "c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
    "\n",
    "u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
    "c6 = Dropout(0.2) (c6)\n",
    "c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
    "\n",
    "u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
    "c7 = Dropout(0.2) (c7)\n",
    "c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
    "\n",
    "u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
    "c8 = Dropout(0.1) (c8)\n",
    "c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
    "\n",
    "u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
    "c9 = Dropout(0.1) (c9)\n",
    "c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "checkpointer = ModelCheckpoint('model-dsbowl2018-1.h5', verbose=1, save_best_only=True)\n",
    "results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=16, epochs=5, \n",
    "                    callbacks=[earlystopper, checkpointer, cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(results.history.keys())\n",
    "\n",
    "# Summarize history for loss\n",
    "plt.plot(results.history['loss'])\n",
    "plt.plot(results.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Summarize history for mean_iou\n",
    "plt.plot(results.history['acc'])\n",
    "plt.plot(results.history['val_acc'])\n",
    "plt.title('model mean iou')\n",
    "plt.ylabel('mean_iou')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Results and Plots\n",
    "# model.summary()\n",
    "print(\"UNET ARCHITECTURE\")\n",
    "print (\"-------------------------------------------------------------\")\n",
    "print(\"Max num of epochs: %d\" % 50)\n",
    "print(\"Optimizer: %s\" % 'ADAM')\n",
    "print(\"Batch size: %d\" % 16)\n",
    "print(\"Loss function: %s\" % 'Binary Cross-Entropy')\n",
    "print(\"Validation data percentage: %d\" % 10)\n",
    "print(\"Early stoppping: %s\" % 'Yes')\n",
    "\n",
    "ep = 5;\n",
    "a = results.history[\"acc\"]\n",
    "b = results.history[\"loss\"]\n",
    "c = results.history[\"val_acc\"]\n",
    "d = results.history[\"val_loss\"]\n",
    "e = cb.times\n",
    "print (\"-------------------------------------------------------------\")\n",
    "header = \"#\"+\"    \"+\"Time sec\"+\"      \"+\"Tr_acc\"+\"     \"+\"Tr_loss\"+\"      \"+\"Vl_acc\"+\"     \"+\"Vl_loss\"\n",
    "print(header)\n",
    "print (\"-------------------------------------------------------------\")\n",
    "for l in range(ep):\n",
    "    str = \"%d\\t\\t%f\\t\\t%f\\t\\t%f\\t\\t%f\\t\\t%f\" % (l, round(e[l],4),round(a[l],4),round(b[l],4),round(c[l],4),d[l])\n",
    "    print (str.expandtabs(2))\n",
    "print (\"-------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on train and validation tests\n",
    "model = load_model('model-dsbowl2018-1.h5', custom_objects={'mean_iou': mean_iou})\n",
    "preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\n",
    "preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check on random training samples\n",
    "ix = random.randint(0, len(preds_train_t))\n",
    "imshow(X_train[ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_train_t[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check on random validation samples\n",
    "ix = random.randint(0, len(preds_val_t))\n",
    "imshow(X_train[int(X_train.shape[0]*0.9):][ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[int(Y_train.shape[0]*0.9):][ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_val_t[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Against Abdomen Pictures\n",
    "TEST_PATH = '/Users/lydiazoghbi/Desktop/Skin Detection/testing data/'\n",
    "test_id = next(os.walk(TEST_PATH))[2]\n",
    "test_id.sort()\n",
    "\n",
    "test = np.zeros((len(test_id), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(test_id), total=len(test_id)):\n",
    "    path = TEST_PATH + id_\n",
    "    img = imread(path)[:,:,:IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    test[n] = img\n",
    "    \n",
    "# Actual Predictions\n",
    "preds_test = model.predict(test[:int(test.shape[0])], verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Predictions\n",
    "ix = random.randint(0, len(test_id))\n",
    "imshow(test[ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_test_t[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Accuracy for Abdomen Set\n",
    "ABD_PATH = '/Users/lydiazoghbi/Desktop/Skin Detection/Segmentation/Skin_Datasets/Dataset_Test/testing_data/'\n",
    "MSK_PATH = '/Users/lydiazoghbi/Desktop/Skin Detection/Segmentation/Skin_Datasets/Dataset_Test/ground_truth/'\n",
    "abd_ids = next(os.walk(ABD_PATH))[2]\n",
    "msk_ids = next(os.walk(MSK_PATH))[2]\n",
    "abd_ids.sort()\n",
    "msk_ids.sort()\n",
    "msk_ids = msk_ids[1:]\n",
    "\n",
    "abd = np.zeros((len(abd_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "msk = np.zeros((len(msk_ids), IMG_HEIGHT, IMG_WIDTH), dtype=np.uint8)\n",
    "\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(abd_ids), total=len(abd_ids)):\n",
    "    path = ABD_PATH + id_\n",
    "    img = imread(path)[:,:,:IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    abd[n] = img\n",
    "    \n",
    "for n, id_ in tqdm(enumerate(msk_ids), total=len(msk_ids)):\n",
    "    path = MSK_PATH + id_\n",
    "    img = imread(path)\n",
    "    \n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
    "                                      preserve_range=True)\n",
    "    img = (img > 15).astype(np.uint8)\n",
    "    msk[n] = img\n",
    "    \n",
    "# Actual Predictions\n",
    "preds_test = model.predict(abd[:int(test.shape[0])], verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
