{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.ops import nn_ops\n",
    "from tensorflow.python.keras import initializers, regularizers, constraints\n",
    "from tensorflow.python.keras.utils import conv_utils\n",
    "from tensorflow.python.keras.utils import tf_utils\n",
    "\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.python.keras.layers import Input, Layer, Flatten\n",
    "from tensorflow.python.keras.layers.core import Activation, Reshape\n",
    "from tensorflow.python.keras.layers.convolutional import Convolution2D\n",
    "from tensorflow.python.keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPoolingWithArgmax2D(Layer):\n",
    "\n",
    "    def __init__(self, pool_size=(2, 2), strides=(2, 2), padding='same', **kwargs):\n",
    "        super(MaxPoolingWithArgmax2D, self).__init__(**kwargs)\n",
    "        self.pool_size = conv_utils.normalize_tuple(pool_size, 2, 'pool_size')\n",
    "        self.strides = conv_utils.normalize_tuple(strides, 2, 'strides')\n",
    "        self.padding = conv_utils.normalize_padding(padding)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        ksize = [1, self.pool_size[0], self.pool_size[1], 1]\n",
    "        strides = [1, self.strides[0], self.strides[1], 1]\n",
    "        padding = self.padding.upper()\n",
    "        output, argmax = nn_ops.max_pool_with_argmax(inputs, ksize, strides, padding)\n",
    "        argmax = tf.cast(argmax, K.floatx())\n",
    "        return [output, argmax]\n",
    "    \n",
    "    @tf_utils.shape_type_conversion\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        ratio = (1, 2, 2, 1)\n",
    "        output_shape = [dim // ratio[idx] if dim is not None else None for idx, dim in enumerate(input_shape)]\n",
    "        output_shape = tuple(output_shape)\n",
    "        return [output_shape, output_shape]\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return 2 * [None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxUnpooling2D(Layer):\n",
    "\n",
    "    def __init__(self, size=(2, 2), **kwargs):\n",
    "        super(MaxUnpooling2D, self).__init__(**kwargs)\n",
    "        self.size = conv_utils.normalize_tuple(size, 2, 'size')\n",
    "\n",
    "    def call(self, inputs, output_shape=None):\n",
    "        updates, mask = inputs[0], inputs[1]\n",
    "        with tf.variable_scope(self.name):\n",
    "            mask = tf.cast(mask, 'int32')\n",
    "            input_shape = tf.shape(updates, out_type='int32')\n",
    "            #  calculation new shape\n",
    "            if output_shape is None:\n",
    "                output_shape = (input_shape[0], input_shape[1] * self.size[0], input_shape[2] * self.size[1], input_shape[3])\n",
    "            \n",
    "            # calculation indices for batch, height, width and feature maps\n",
    "            one_like_mask = K.ones_like(mask, dtype='int32')\n",
    "            batch_shape = K.concatenate([[input_shape[0]], [1], [1], [1]], axis=0)\n",
    "            batch_range = K.reshape(tf.range(output_shape[0], dtype='int32'), shape=batch_shape)\n",
    "            b = one_like_mask * batch_range\n",
    "            y = mask // (output_shape[2] * output_shape[3])\n",
    "            x = (mask // output_shape[3]) % output_shape[2]\n",
    "            feature_range = tf.range(output_shape[3], dtype='int32')\n",
    "            f = one_like_mask * feature_range\n",
    "            \n",
    "            # transpose indices & reshape update values to one dimension\n",
    "            updates_size = tf.size(updates)\n",
    "            indices = K.transpose(K.reshape(K.stack([b, y, x, f]), [4, updates_size]))\n",
    "            values = K.reshape(updates, [updates_size])\n",
    "            ret = tf.scatter_nd(indices, values, output_shape)\n",
    "            return ret\n",
    "    \n",
    "    @tf_utils.shape_type_conversion\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        mask_shape = input_shape[1]\n",
    "        output_shape = [mask_shape[0], mask_shape[1] * self.size[0], mask_shape[2] * self.size[1], mask_shape[3]]\n",
    "        return tuple(output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build SEGNET model\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128\n",
    "IMG_CHANNELS = 3\n",
    "n_labels = 2\n",
    "output_mode = \"softmax\"\n",
    "\n",
    "inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "\n",
    "# Encoder\n",
    "\n",
    "conv_1 = Convolution2D(64, (3, 3), kernel_initializer='he_normal', padding=\"same\")(inputs)\n",
    "conv_1 = BatchNormalization()(conv_1)\n",
    "conv_1 = Activation(\"relu\")(conv_1)\n",
    "conv_2 = Convolution2D(64, (3, 3), kernel_initializer='he_normal', padding=\"same\")(conv_1)\n",
    "conv_2 = BatchNormalization()(conv_2)\n",
    "conv_2 = Activation(\"relu\")(conv_2)\n",
    "\n",
    "pool_1, mask_1 = MaxPoolingWithArgmax2D((2,2))(conv_2)\n",
    "\n",
    "conv_3 = Convolution2D(128, (3, 3), kernel_initializer='he_normal', padding=\"same\")(pool_1)\n",
    "conv_3 = BatchNormalization()(conv_3)\n",
    "conv_3 = Activation(\"relu\")(conv_3)\n",
    "conv_4 = Convolution2D(128, (3, 3), kernel_initializer='he_normal', padding=\"same\")(conv_3)\n",
    "conv_4 = BatchNormalization()(conv_4)\n",
    "conv_4 = Activation(\"relu\")(conv_4)\n",
    "\n",
    "pool_2, mask_2 = MaxPoolingWithArgmax2D((2,2))(conv_4)\n",
    "\n",
    "conv_5 = Convolution2D(256, (3, 3), kernel_initializer='he_normal', padding=\"same\")(pool_2)\n",
    "conv_5 = BatchNormalization()(conv_5)\n",
    "conv_5 = Activation(\"relu\")(conv_5)\n",
    "conv_6 = Convolution2D(256, (3, 3), kernel_initializer='he_normal', padding=\"same\")(conv_5)\n",
    "conv_6 = BatchNormalization()(conv_6)\n",
    "conv_6 = Activation(\"relu\")(conv_6)\n",
    "conv_7 = Convolution2D(256, (3, 3), kernel_initializer='he_normal', padding=\"same\")(conv_6)\n",
    "conv_7 = BatchNormalization()(conv_7)\n",
    "conv_7 = Activation(\"relu\")(conv_7)\n",
    "\n",
    "pool_3, mask_3 = MaxPoolingWithArgmax2D((2,2))(conv_7)\n",
    "\n",
    "conv_8 = Convolution2D(512, (3, 3), kernel_initializer='he_normal', padding=\"same\")(pool_3)\n",
    "conv_8 = BatchNormalization()(conv_8)\n",
    "conv_8 = Activation(\"relu\")(conv_8)\n",
    "conv_9 = Convolution2D(512, (3, 3), kernel_initializer='he_normal', padding=\"same\")(conv_8)\n",
    "conv_9 = BatchNormalization()(conv_9)\n",
    "conv_9 = Activation(\"relu\")(conv_9)\n",
    "conv_10 = Convolution2D(512, (3, 3), kernel_initializer='he_normal', padding=\"same\")(conv_9)\n",
    "conv_10 = BatchNormalization()(conv_10)\n",
    "conv_10 = Activation(\"relu\")(conv_10)\n",
    "\n",
    "pool_4, mask_4 = MaxPoolingWithArgmax2D((2,2))(conv_10)\n",
    "\n",
    "conv_11 = Convolution2D(512, (3, 3), kernel_initializer='he_normal', padding=\"same\")(pool_4)\n",
    "conv_11 = BatchNormalization()(conv_11)\n",
    "conv_11 = Activation(\"relu\")(conv_11)\n",
    "conv_12 = Convolution2D(512, (3, 3), kernel_initializer='he_normal', padding=\"same\")(conv_11)\n",
    "conv_12 = BatchNormalization()(conv_12)\n",
    "conv_12 = Activation(\"relu\")(conv_12)\n",
    "conv_13 = Convolution2D(512, (3, 3), kernel_initializer='he_normal', padding=\"same\")(conv_12)\n",
    "conv_13 = BatchNormalization()(conv_13)\n",
    "conv_13 = Activation(\"relu\")(conv_13)\n",
    "\n",
    "pool_5, mask_5 = MaxPoolingWithArgmax2D((2,2))(conv_13)\n",
    "\n",
    "# Decoder\n",
    "\n",
    "unpool_1 = MaxUnpooling2D((2,2))([pool_5, mask_5])\n",
    "\n",
    "conv_14 = Convolution2D(512, (3, 3), kernel_initializer='he_normal', padding=\"same\")(unpool_1)\n",
    "conv_14 = BatchNormalization()(conv_14)\n",
    "conv_14 = Activation(\"relu\")(conv_14)\n",
    "conv_15 = Convolution2D(512, (3, 3), kernel_initializer='he_normal', padding=\"same\")(conv_14)\n",
    "conv_15 = BatchNormalization()(conv_15)\n",
    "conv_15 = Activation(\"relu\")(conv_15)\n",
    "conv_16 = Convolution2D(512, (3, 3), kernel_initializer='he_normal', padding=\"same\")(conv_15)\n",
    "conv_16 = BatchNormalization()(conv_16)\n",
    "conv_16 = Activation(\"relu\")(conv_16)\n",
    "\n",
    "unpool_2 = MaxUnpooling2D((2,2))([conv_16, mask_4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
