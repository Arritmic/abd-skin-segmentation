{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "seed = 42\n",
    "random.seed = seed\n",
    "np.random.seed = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Training Data (Original+Mask) DONT RUN IN THIS CODE \n",
    "# Dataset 1: HGR\n",
    "TRAIN_PATH1 = ['/home/lalzogbi/Documents/Skin_Datasets/Dataset1_HGR/original_images/']\n",
    "MASK_PATH1 = ['/home/lalzogbi/Documents/Skin_Datasets/Dataset1_HGR/skin_masks/']\n",
    "train_ids1 = next(os.walk(TRAIN_PATH1[0]))[2]\n",
    "mask_ids1 = next(os.walk(MASK_PATH1[0]))[2]\n",
    "train_ids1.sort()\n",
    "mask_ids1.sort()\n",
    "TRAIN_PATH1 = TRAIN_PATH1*len(train_ids1)\n",
    "MASK_PATH1 = MASK_PATH1*len(train_ids1)\n",
    "\n",
    "# Dataset 4: Pratheepan\n",
    "TRAIN_PATH2 = ['/home/lalzogbi/Documents/Skin_Datasets/Dataset4_Pratheepan/original_images/']\n",
    "MASK_PATH2 = ['/home/lalzogbi/Documents/Skin_Datasets/Dataset4_Pratheepan/skin_masks/']\n",
    "train_ids2 = next(os.walk(TRAIN_PATH2[0]))[2]\n",
    "mask_ids2 = next(os.walk(MASK_PATH2[0]))[2]\n",
    "train_ids2.sort()\n",
    "mask_ids2.sort()\n",
    "TRAIN_PATH2 = TRAIN_PATH2*len(train_ids2)\n",
    "MASK_PATH2 = MASK_PATH2*len(train_ids2)\n",
    "\n",
    "# Dataset 5: VDM\n",
    "TRAIN_PATH3 = ['/home/lalzogbi/Documents/Skin_Datasets/Dataset5_VDM/original_images/']\n",
    "MASK_PATH3 = ['/home/lalzogbi/Documents/Skin_Datasets/Dataset5_VDM/skin_masks/']\n",
    "train_id3 = next(os.walk(TRAIN_PATH3[0]))[2]\n",
    "mask_id3 = next(os.walk(MASK_PATH3[0]))[2]\n",
    "train_id3.sort()\n",
    "mask_id3.sort()\n",
    "train_ids3 = train_id3[1:]\n",
    "mask_ids3 = mask_id3[1:]\n",
    "TRAIN_PATH3 = TRAIN_PATH3*len(train_ids3)\n",
    "MASK_PATH3 = MASK_PATH3*len(train_ids3)\n",
    "\n",
    "# Dataset 6: SFA\n",
    "TRAIN_PATH4 = ['/home/lalzogbi/Documents/Skin_Datasets/Dataset6_SFA/original_images/']\n",
    "MASK_PATH4 = ['/home/lalzogbi/Documents/Skin_Datasets/Dataset6_SFA/skin_masks/']\n",
    "train_ids4 = next(os.walk(TRAIN_PATH4[0]))[2]\n",
    "mask_ids4 = next(os.walk(MASK_PATH4[0]))[2]\n",
    "train_ids4.sort()\n",
    "mask_ids4.sort()\n",
    "TRAIN_PATH4 = TRAIN_PATH4*len(train_ids4)\n",
    "MASK_PATH4 = MASK_PATH4*len(train_ids4)\n",
    "\n",
    "# Dataset 2: TDSD\n",
    "TRAIN_PATH5 = ['/home/lalzogbi/Documents/Skin_Datasets/Dataset2_TDSD/original_images/']\n",
    "MASK_PATH5 = ['/home/lalzogbi/Documents/Skin_Datasets/Dataset2_TDSD/skin_masks/']\n",
    "train_ids5 = next(os.walk(TRAIN_PATH5[0]))[2]\n",
    "mask_ids5 = next(os.walk(MASK_PATH5[0]))[2]\n",
    "train_ids5.sort()\n",
    "mask_ids5.sort()\n",
    "TRAIN_PATH5 = TRAIN_PATH5*len(train_ids5)\n",
    "MASK_PATH5 = MASK_PATH5*len(train_ids5)\n",
    "\n",
    "# Dataset 3: Schmugge\n",
    "TRAIN_PATH6 = ['/home/lalzogbi/Documents/Skin_Datasets/Dataset3_Schmugge/original_images/']\n",
    "MASK_PATH6 = ['/home/lalzogbi/Documents/Skin_Datasets/Dataset3_Schmugge/skin_masks/']\n",
    "train_ids6 = next(os.walk(TRAIN_PATH6[0]))[2]\n",
    "mask_ids6 = next(os.walk(MASK_PATH6[0]))[2]\n",
    "train_ids6.sort()\n",
    "mask_ids6.sort()\n",
    "TRAIN_PATH6 = TRAIN_PATH6*len(train_ids6)\n",
    "MASK_PATH6 = MASK_PATH6*len(train_ids6)\n",
    "\n",
    "# Combine everything\n",
    "TRAIN_PATH = np.concatenate((TRAIN_PATH1,TRAIN_PATH2,TRAIN_PATH3,TRAIN_PATH4,TRAIN_PATH5,TRAIN_PATH6))\n",
    "MASK_PATH = np.concatenate((MASK_PATH1,MASK_PATH2,MASK_PATH3,MASK_PATH4,MASK_PATH5,MASK_PATH6))\n",
    "train_ids = np.concatenate((train_ids1,train_ids2,train_ids3,train_ids4,train_ids5,train_ids6))\n",
    "mask_ids = np.concatenate((mask_ids1,mask_ids2,mask_ids3,mask_ids4,mask_ids5,mask_ids6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing train images and masks ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3780/3780 [00:35<00:00, 105.29it/s]\n",
      "100%|██████████| 3780/3780 [00:07<00:00, 485.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get and resize train images and masks DONT RUN IN THIS CODE\n",
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = TRAIN_PATH[n] + id_\n",
    "    img = imread(path)[:,:,:IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_train[n] = img\n",
    "\n",
    "for n, id_ in tqdm(enumerate(mask_ids), total=len(mask_ids)):\n",
    "    path = MASK_PATH[n] + id_\n",
    "    img = imread(path)\n",
    "    if n in range(899,977):\n",
    "        img = img[:,:,1]\n",
    "    img = np.expand_dims(resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
    "                                      preserve_range=True), axis=-1)\n",
    "    Y_train[n] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Features and Corresponding Labels\n",
    "dat = X_train[0]\n",
    "dat = dat.reshape(16384,3)\n",
    "hsv = cv.cvtColor(X_train[0], cv.COLOR_RGB2HSV)\n",
    "hsv = hsv.reshape(16384,3)\n",
    "lab = cv.cvtColor(X_train[0], cv.COLOR_RGB2Lab)\n",
    "lab = lab.reshape(16384,3)\n",
    "L = Y_train[0]\n",
    "L = L.reshape(16384,1)\n",
    "dat = np.concatenate((dat,hsv,lab,L),axis=1)\n",
    "\n",
    "for i in range(len(train_ids)-1):\n",
    "    i = i+1\n",
    "    a = X_train[i]\n",
    "    b = a.reshape(16384,3)\n",
    "    hsv = cv.cvtColor(X_train[i], cv.COLOR_RGB2HSV)\n",
    "    hsv = hsv.reshape(16384,3)\n",
    "    lab = cv.cvtColor(X_train[0], cv.COLOR_RGB2Lab)\n",
    "    lab = lab.reshape(16384,3)\n",
    "    L = Y_train[i]\n",
    "    L = L.reshape(16384,1)\n",
    "    dat_temp = np.concatenate((b,hsv,lab,L),axis=1)\n",
    "    dat = np.concatenate((dat,dat_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(dat)\n",
    "feat = dat[0:300000,0:9]\n",
    "labels = dat[0:300000,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 210000 samples, validate on 90000 samples\n",
      "Epoch 1/50\n",
      "210000/210000 [==============================] - 80s 382us/step - loss: 0.3241 - acc: 0.8703 - val_loss: 0.3175 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.31750, saving model to model-features-5Feb2019.h5\n",
      "Epoch 2/50\n",
      "210000/210000 [==============================] - 80s 380us/step - loss: 0.2729 - acc: 0.8952 - val_loss: 0.2854 - val_acc: 0.8885\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.31750 to 0.28542, saving model to model-features-5Feb2019.h5\n",
      "Epoch 3/50\n",
      "210000/210000 [==============================] - 80s 380us/step - loss: 0.2686 - acc: 0.8967 - val_loss: 0.2561 - val_acc: 0.9046\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.28542 to 0.25611, saving model to model-features-5Feb2019.h5\n",
      "Epoch 4/50\n",
      "210000/210000 [==============================] - 80s 379us/step - loss: 0.2666 - acc: 0.8979 - val_loss: 0.2456 - val_acc: 0.9038\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.25611 to 0.24558, saving model to model-features-5Feb2019.h5\n",
      "Epoch 5/50\n",
      "210000/210000 [==============================] - 80s 380us/step - loss: 0.2655 - acc: 0.8977 - val_loss: 0.2600 - val_acc: 0.8999\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.24558\n",
      "Epoch 6/50\n",
      "210000/210000 [==============================] - 80s 379us/step - loss: 0.2643 - acc: 0.8977 - val_loss: 0.2782 - val_acc: 0.8918\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.24558\n",
      "Epoch 7/50\n",
      "210000/210000 [==============================] - 79s 378us/step - loss: 0.2637 - acc: 0.8978 - val_loss: 0.2523 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.24558\n",
      "Epoch 8/50\n",
      "210000/210000 [==============================] - 80s 379us/step - loss: 0.2650 - acc: 0.8987 - val_loss: 0.2683 - val_acc: 0.9010\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.24558\n",
      "Epoch 9/50\n",
      "210000/210000 [==============================] - 80s 380us/step - loss: 0.2651 - acc: 0.8985 - val_loss: 0.2884 - val_acc: 0.8860\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.24558\n",
      "Epoch 10/50\n",
      "210000/210000 [==============================] - 79s 378us/step - loss: 0.2647 - acc: 0.8990 - val_loss: 0.2452 - val_acc: 0.9032\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.24558 to 0.24523, saving model to model-features-5Feb2019.h5\n",
      "Epoch 11/50\n",
      "210000/210000 [==============================] - 79s 377us/step - loss: 0.2667 - acc: 0.8982 - val_loss: 0.2724 - val_acc: 0.9033\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.24523\n",
      "Epoch 12/50\n",
      "210000/210000 [==============================] - 80s 380us/step - loss: 0.2673 - acc: 0.8985 - val_loss: 0.2491 - val_acc: 0.9025\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.24523\n",
      "Epoch 13/50\n",
      "210000/210000 [==============================] - 80s 379us/step - loss: 0.2698 - acc: 0.8973 - val_loss: 0.2420 - val_acc: 0.9071\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.24523 to 0.24198, saving model to model-features-5Feb2019.h5\n",
      "Epoch 14/50\n",
      "210000/210000 [==============================] - 80s 380us/step - loss: 0.2682 - acc: 0.8978 - val_loss: 0.2547 - val_acc: 0.9064\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.24198\n",
      "Epoch 15/50\n",
      "210000/210000 [==============================] - 79s 378us/step - loss: 0.2718 - acc: 0.8966 - val_loss: 0.2453 - val_acc: 0.9049\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.24198\n",
      "Epoch 16/50\n",
      "210000/210000 [==============================] - 80s 381us/step - loss: 0.2708 - acc: 0.8975 - val_loss: 0.2485 - val_acc: 0.9043\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.24198\n",
      "Epoch 17/50\n",
      "210000/210000 [==============================] - 79s 377us/step - loss: 0.2685 - acc: 0.8978 - val_loss: 0.2789 - val_acc: 0.8981\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.24198\n",
      "Epoch 18/50\n",
      "210000/210000 [==============================] - 80s 380us/step - loss: 0.2715 - acc: 0.8979 - val_loss: 0.2895 - val_acc: 0.9029\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.24198\n",
      "Epoch 19/50\n",
      "210000/210000 [==============================] - 80s 379us/step - loss: 0.2750 - acc: 0.8958 - val_loss: 0.2536 - val_acc: 0.9006\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.24198\n",
      "Epoch 20/50\n",
      "210000/210000 [==============================] - 80s 380us/step - loss: 0.2795 - acc: 0.8955 - val_loss: 0.2555 - val_acc: 0.9051\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.24198\n",
      "Epoch 21/50\n",
      "210000/210000 [==============================] - 79s 375us/step - loss: 0.2742 - acc: 0.8964 - val_loss: 0.2609 - val_acc: 0.9003\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.24198\n",
      "Epoch 22/50\n",
      "210000/210000 [==============================] - 79s 378us/step - loss: 0.2811 - acc: 0.8950 - val_loss: 0.2735 - val_acc: 0.8972\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.24198\n",
      "Epoch 23/50\n",
      "210000/210000 [==============================] - 79s 378us/step - loss: 0.2845 - acc: 0.8938 - val_loss: 0.2693 - val_acc: 0.8975\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.24198\n",
      "Epoch 24/50\n",
      "210000/210000 [==============================] - 79s 378us/step - loss: 0.2810 - acc: 0.8932 - val_loss: 0.2622 - val_acc: 0.9002\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.24198\n",
      "Epoch 25/50\n",
      "210000/210000 [==============================] - 79s 376us/step - loss: 0.2925 - acc: 0.8917 - val_loss: 0.2849 - val_acc: 0.9009\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.24198\n",
      "Epoch 26/50\n",
      "210000/210000 [==============================] - 79s 377us/step - loss: 0.2877 - acc: 0.8908 - val_loss: 0.2841 - val_acc: 0.8884\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.24198\n",
      "Epoch 27/50\n",
      "210000/210000 [==============================] - 79s 376us/step - loss: 0.2994 - acc: 0.8912 - val_loss: 0.2758 - val_acc: 0.8938\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.24198\n",
      "Epoch 28/50\n",
      "210000/210000 [==============================] - 79s 378us/step - loss: 0.2906 - acc: 0.8912 - val_loss: 0.2697 - val_acc: 0.8975\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.24198\n",
      "Epoch 29/50\n",
      "210000/210000 [==============================] - 79s 378us/step - loss: 0.3135 - acc: 0.8818 - val_loss: 0.2960 - val_acc: 0.8976\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.24198\n",
      "Epoch 30/50\n",
      "210000/210000 [==============================] - 80s 379us/step - loss: 0.2882 - acc: 0.8898 - val_loss: 0.2829 - val_acc: 0.8919\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.24198\n",
      "Epoch 31/50\n",
      "210000/210000 [==============================] - 79s 377us/step - loss: 0.3260 - acc: 0.8856 - val_loss: 0.2847 - val_acc: 0.8897\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.24198\n",
      "Epoch 32/50\n",
      "210000/210000 [==============================] - 79s 378us/step - loss: 0.2887 - acc: 0.8879 - val_loss: 0.2669 - val_acc: 0.9003\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.24198\n",
      "Epoch 33/50\n",
      "210000/210000 [==============================] - 79s 378us/step - loss: 0.3130 - acc: 0.8899 - val_loss: 0.2993 - val_acc: 0.8897\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.24198\n",
      "Epoch 34/50\n",
      "210000/210000 [==============================] - 79s 379us/step - loss: 0.2965 - acc: 0.8891 - val_loss: 0.2756 - val_acc: 0.8983\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.24198\n",
      "Epoch 35/50\n",
      "210000/210000 [==============================] - 79s 377us/step - loss: 0.9114 - acc: 0.8659 - val_loss: 0.4927 - val_acc: 0.8808\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.24198\n",
      "Epoch 36/50\n",
      "210000/210000 [==============================] - 79s 378us/step - loss: 0.3148 - acc: 0.8786 - val_loss: 0.2893 - val_acc: 0.8949\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.24198\n",
      "Epoch 37/50\n",
      "210000/210000 [==============================] - 80s 379us/step - loss: 0.3051 - acc: 0.8882 - val_loss: 0.2802 - val_acc: 0.8917\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.24198\n",
      "Epoch 38/50\n",
      "210000/210000 [==============================] - 80s 379us/step - loss: 0.2918 - acc: 0.8907 - val_loss: 0.2917 - val_acc: 0.8934\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.24198\n",
      "Epoch 39/50\n",
      "210000/210000 [==============================] - 79s 378us/step - loss: 0.3231 - acc: 0.8872 - val_loss: 0.2640 - val_acc: 0.9016\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.24198\n",
      "Epoch 40/50\n",
      "210000/210000 [==============================] - 79s 379us/step - loss: 0.5592 - acc: 0.8761 - val_loss: 0.2740 - val_acc: 0.8897\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.24198\n",
      "Epoch 41/50\n",
      "210000/210000 [==============================] - 79s 377us/step - loss: 0.3039 - acc: 0.8844 - val_loss: 0.2601 - val_acc: 0.8976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00041: val_loss did not improve from 0.24198\n",
      "Epoch 42/50\n",
      "210000/210000 [==============================] - 80s 380us/step - loss: 1.6962 - acc: 0.8354 - val_loss: 3.8100 - val_acc: 0.7636\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.24198\n",
      "Epoch 43/50\n",
      "210000/210000 [==============================] - 80s 379us/step - loss: 2.2319 - acc: 0.8126 - val_loss: 0.3244 - val_acc: 0.8785\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.24198\n",
      "Epoch 44/50\n",
      "210000/210000 [==============================] - 79s 378us/step - loss: 0.3330 - acc: 0.8842 - val_loss: 0.3239 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.24198\n",
      "Epoch 45/50\n",
      "210000/210000 [==============================] - 79s 378us/step - loss: 0.3347 - acc: 0.8834 - val_loss: 0.2702 - val_acc: 0.8952\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.24198\n",
      "Epoch 46/50\n",
      "210000/210000 [==============================] - 80s 380us/step - loss: 0.3096 - acc: 0.8838 - val_loss: 0.2763 - val_acc: 0.8981\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.24198\n",
      "Epoch 47/50\n",
      " 35860/210000 [====>.........................] - ETA: 59s - loss: 0.3357 - acc: 0.8818"
     ]
    }
   ],
   "source": [
    "# Build the network\n",
    "model = Sequential()\n",
    "model.add(Dense(9, input_dim=9, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2, input_shape=(32,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2, input_shape=(64,)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2, input_shape=(128,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2, input_shape=(64,)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2, input_shape=(32,)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "checkpointer = ModelCheckpoint('model-features-5Feb2019.h5', verbose=1, save_best_only=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(feat, labels,validation_split=0.3, epochs=50, batch_size=10, shuffle=True, \n",
    "          callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
